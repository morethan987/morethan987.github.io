


[{"content":" 一个新型的人脑启发式架构，在现有时序无关的神经元模型的基础上引入了\u0026quot;时序\u0026quot;概念，涌现出一系列类似人脑的现象 前言 # 关注到这篇论文其实就是因为其宣称的那种\u0026quot;奇妙\u0026quot;的涌现现象，将时序信息引入神经元模型之后产生了类似人类思维模式的注意力现象。这些现象并非人为设计的，而是在训练过程中自然产生的，这是最令人振奋的。\n最直观的例子就是官方给出的\u0026quot;迷宫模型\u0026quot;，从可视化的结果可以直观地看到，模型的注意力焦点在迷宫中游走，就像人类求解迷宫问题一样。另外官方还给出了一个可交互的展示网页：Demo，在这个网页中你可以直接指挥模型求解迷宫，并实时查看模型的注意力焦点。\n另外，官方的代码仓库中配置了详尽的说明文档和代码注释，代码文件的切分也非常简洁直观，有一种程序员才懂的\u0026quot;艺术感\u0026quot;。\n在阅读了大量的屎山代码之后，可能才会对代码的\u0026quot;优雅\u0026quot;程度有所体会😇并深刻理解这份\u0026quot;优雅\u0026quot;背后的工作量 引入 # 神经网络最初受生物大脑启发，却与生物大脑差异巨大。生物大脑展现出随时间演变的复杂神经动力学过程，而现代神经网络为了便于大规模深度学习，可以摒弃了\u0026quot;时序\u0026quot;特征。\n关于为什么要开展这项研究，官方论文中已经有了非常明确的表述，无需多言：\n\u0026ldquo;为何开展此项研究？诚然，现代人工智能在诸多实践领域展现出的卓越性能似乎表明，对神经动力学的模拟实无必要，抑或显式考量智能的时间维度实属反实用之举。然而，人类智能具有高度灵活性、数据高效性以及优异的未见情境外推能力，且存在于学习与适应皆与时间之箭紧密关联的开放世界中。因此，人类智能天然具备常识运用、本体论推理能力、透明性/可解释性以及强大的泛化能力——这些特质在现有人工智能中尚未得到令人信服的体现。\u0026rdquo;\n这篇文章的核心技术贡献如下所示：\n解耦的内部时间维度 神经元层面的模型(NLMs) 神经活动同步 当然，在没有详细看代码实现的情况下，光看这些名词是没有意义的。但是作者的思路和观点还是可以了解：\n推理模型和循环：作者锐评了当前推理模型，指出\u0026quot;继续扩展当前模型架构\u0026quot;这条技术路线已经被很多研究质疑。而使用循环技术也的确能够让现有模型架构产生更加良好的表现，但是作者认为，循环机制很重要，但是被循环机制解锁的神经元活动之间的精确时序与交互同样重要 有趣的副作用：CTM 内部的循环类似于人类的思考，在没有任何显式的监督函数引导的情况下就能够为不同难度的任务自动分配合适的计算资源，简单的任务将会提前终止计算，而复杂的任务将会进行更加深入的计算 信息可以被编码在时序动态中，这将赋予网络更加强大的信息压缩能力 说明一下我对第三点的思考，按照\u0026quot;压缩即智能\u0026quot;的观点，将将信息编码到时序动态中将极大地提高网络的信息\u0026quot;压缩率\u0026quot;，从某种程度上来说也就提升了\u0026quot;智能\u0026quot; 最后作者也明确了自己这个研究的目的所在：\n\u0026ldquo;通过CTM显式建模神经时序机制，我们旨在为开发更具生物合理性且高性能的人工智能系统开辟新路径。\u0026rdquo;\n方法 # CTM架构概述：①突触模型（权重以蓝线表示）通过模拟神经元间相互作用生成预激活值。每个神经元会保留 ②预激活历史记录，其中最新数据被 ③神经元级模型（权重以红线表示）用于产生 ④后激活值。系统同时维护 ⑤后激活历史记录，并据此计算⑥同步矩阵。基于该矩阵 ⑦筛选神经元对，由此产生的 ⑧潜表征被CTM用于 ⑨生成输出并通过交叉注意力机制调节数据。经调节的数据（如注意力输出）会 ⑩与后激活值拼接，作为下一内部时钟步的输入\n如果只是单纯的引入时间维度的话，传统的 RNN 架构也能够实现，但 CTM 的创新之处在于：\n使用神经元级模型取代了传统的激活函数 使用神经同步作为潜在表征来调制数据并生成输出 连续思考：内部序列维度 # $$ t\\in \\{1,\\dots,T\\} $$图中参数右上角的角标就指代的是某一个特定的时间步，而每一个时间步中都会进行一次图中完整的计算流程(从①到⑩)\n这种内部维度并非全新的概念，RNN 和 Transformer 中都有使用。但是传统的架构按照数据输入的顺序来逐步处理，这隐含地将内部的时间维度与数据的输入顺序挂钩了。\n举个例子，RNN 中也有内部时间维度的概念，只是每一个时间步模型都会接受一个新的 token 输入，然后根据内部隐状态去产生下一个 token 并更新内部隐状态。如果只看 token 的输入就会发现我们其实是默认将数据内在的顺序作为模型的内部时间维度\nTransformer 本身是\u0026quot;无序\u0026quot;的：每一个时间步注意力机制都会并行处理原来所有的 token 或许这也是其强大所在🤔真正和输入数据顺序相关的步骤在于\u0026quot;位置嵌入\u0026quot; 而 CTM 则完全解耦了这种关联，让内部的处理与输入数据无关。不只是顺序无关，还与输入序列的长度无关，这也可能是作者更想强调的🤔\n这种\u0026quot;解耦\u0026quot;使得模型内部的\u0026quot;思考\u0026quot;可以有任意长度，可以迭代地构建和完善内部表征，并且可以扩展到\u0026quot;非序列化\u0026quot;的任务上，例如求解迷宫问题。\n其实目前 CoT 那一系列的技术可以理解为在做\u0026quot;解耦\u0026quot;的工作：数据输入已经摆在那里了，直接生成答案效果不太行，那就多产生一些长度不受数据序列影响的中间 token 也就是所谓的思考过程。但发现在非常简单的问题中模型想太多结果也不太好，怎么办呢？Anthropic 就把\u0026quot;思考多少合适\u0026quot;这个问题丢给了模型使用者，这从工程上也不失为一个明智之举。但 CTM 貌似有望解决这个问题😃其貌似从底层架构上解耦了数据序列与内部时间维度的关系🤔\n如果你想对当前的 CoT 技术有一个更加深入而全面的了解，可以去看看 Why we think - Lil\u0026rsquo;log 里面有更加学术化的严谨表达，但又非常容易理解。\n循环权重：突触模型 # $$ a^t=f_{\\theta_{syn}}(concat(z^t,o^t))\\in R^D $$ 其中 \\(z^t\\in R^D\\) 表示 \\(t\\) 时间步的输入序列，\\(o^t\\) 是上一个时间步计算得出的调制数据，与原来的 \\(z^t\\) 进行拼接后整体送入突触模型进行计算，然后就得出 \\(a^t\\) 也就是预激活向量\n注意这里用的是小写的 \\(z\\) 而大图中使用的是大写的 \\(Z\\)：\\(z\\) 表示作用在单个神经元上的输入向量；而 \\(Z\\) 表示作用在整个模型上的输入，也就是一个矩阵 突触模型本质上就是一个函数 \\(f_{\\theta_{syn}}\\) 可以用多种方式表达，经过实验，原论文中使用了 MLP 来表示这个函数，更具体的就是 U-NET-esque MLP\n然后将最近的 \\(M\\) 个预激活向量用一个矩阵 \\(A^t\\) 存储起来：\n$$ A^t=[a^{t-M+1}\\quad a^{t-M+1}\\dots a^{t}]\\in R^{D\\times M} $$ 历史序列中的前 \\(M\\) 个元素及初始时刻 \\(t=1\\) 的 \\(z\\) 值需要进行初始化，实验表明将其设置为可学习参数能获得最佳效果。\n参数私有化的神经元级模型 # 在突触模型中介绍了单个神经元(突触)是如何处理输入，并产生一个历史记录矩阵。现在假设有 \\(D\\) 个同样的神经元，每一个神经元都有各自的 \\(A^t\\) 我们将其中编号为 \\(d\\) 的神经元的历史记录矩阵写作 \\(A^t_{d}\\)\n然后每一个神经元都会进行如下计算：\n$$ z^{t+1}_{d}=g_{\\theta_{d}}(A^t_{d}) $$\\(\\theta_{d}\\) 表示编号为 \\(d\\) 的神经元私有的计算参数；\\(z^{t+1}_{d}\\) 如其角标所示，就是下一个时间步 \\(d\\) 号神经元的输入，作者称其为后激活向量。而 \\(g_{\\theta_{d}}\\) 就是一个单隐层的 MLP，接受一个 \\(M\\times D\\) 的矩阵 \\(A^t_{d}\\) 输出 \\(z^{t+1}_{d}\\in R^D\\)\n用大白话描述这一步操作就是：每一个神经元都根据自己前 \\(M\\) 次的预激活向量产生下一个输入向量。\n神经元同步：输入与输出的调制 # 这一步是让数据与模型的交互不再依赖某一个时刻的模型状态，而是持续的动态的神经活动。具体而言就是将后激活向量收集起来，形成一个矩阵：\n$$ Z^t = [z^1 \\quad z^2 \\dots z^t]\\in R^{D\\times t} $$然后将神经元同步描述为 \\(Z^t\\) 的内积：\n$$ S^t=Z^t \\cdot (Z^t)^T\\in R^{D\\times D} $$然后对这个神经元同步矩阵进行下采样：从中随机选取 \\(D_{out}\\) 和 \\(D_{action}\\) 个元素值，分别形成两个神经元同步的表征向量，即 \\(S^t_{out}\\in R^{D_{out}}\\) 和 \\(S^t_{action}\\in R^{D_{action}}\\)\n\\(S^t_{out}\\) 被投影到输出空间：\n$$ \\mathbf{y}^t = W_{out}\\cdot S^t_{out} $$而 \\(S^t_{action}\\) 则用于在世界中产生行为(尊重原论文表述，但其实有些迷惑🤔)：\n$$ q^t = W_{in}\\cdot S^t_{action} $$\\(W_{in}\\) 和 \\(W_{out}\\) 都是可学习的矩阵参数\n计算得出的 \\(q^t\\) 会在经过额外的计算产生 \\(o^t\\in R^{d_{input}}\\)，并在第一步中与 \\(z^t\\) 进行拼接，在作者的实验中这个额外的计算一般就是注意力层：\n$$ o^t=Attention(Q=q^t, KV=FeatureExtractor(data)) $$其中 \\(FeatureExtractor(\\cdot)\\) 也是一个神经网络模型，例如 \\(ResNet\\)\n由于 \\(S^t\\) 聚合了当前所有时间步的信息，较晚的时间步可能对结果的影响更大。为了让模型的灵活性更强，引入了一个可学习的衰减系数：\n$$ \\mathbf{R}_{i j}^{t}=\\left[\\begin{array}{llll} \\exp \\left(-r_{i j}(t-1)\\right) \u0026 \\exp \\left(-r_{i j}(t-2)\\right) \u0026 \\cdots \u0026 \\exp (0) \\end{array}\\right]^{\\top} \\in \\mathbb{R}^{t} $$然后用这个衰减系数去放缩原本的神经元同步矩阵的元素值：\n$$ \\mathbf{S}_{i j}^{t}=\\frac{\\left(\\mathbf{Z}_{i}^{t}\\right)^{\\top} \\cdot \\operatorname{diag}\\left(\\mathbf{R}_{i j}^{t}\\right) \\cdot\\left(\\mathbf{Z}_{j}^{t}\\right)}{\\sqrt{\\sum_{\\tau=1}^{t}\\left[\\mathbf{R}_{i j}^{t}\\right]_{\\tau}}} $$ 作者经过实际研究，发现这些可学习的衰减系数很少用到：在 ImageNet 视觉分类任务中在 8196 个衰减系数中只有 3 个是有效的；而在迷宫求解问题中更多一些，但也只有大约 3% 损失函数：在不同时间步中优化 # 这里用分类任务举例子，假设某一个分类任务有 \\(C\\) 个类别，某一个时间步上的损失就是：\n$$ \\mathcal{L}^{t}=\\operatorname{CrossEntropy}\\left(\\mathbf{y}^{t}, y_{\\text {true}}\\right) $$作者还给出了一个置信度向量 \\(C^t\\)：\n$$ C^t=1-\\frac{\\mathcal{L}^{t}}{\\sqrt{ (\\mathcal{L}^{t})^T \\cdot \\mathcal{L}^{t} }} $$然后在所有时间步上收集这些损失就形成了两个矩阵：\\(\\mathcal{L}\\in R^T\\) 和 \\(C\\in R^T\\)\n一个自然产生的问题是：应如何将L降维为标量损失函数以用于学习？本研究的损失函数旨在优化 CTM 在内部时间维度上的性能表现。相较于让模型在某一个特定的时间步输出结果(典型的就是最后一步)，作者采用了动态聚合的策略，整合两个内部时刻的信息：损失最小点和确定性最高点。该方法优势如下：\n促使CTM在多个内部时刻建立有意义的表征与计算 自然形成课程学习效应，模型可先利用后期内部时刻处理复杂计算，再逐步过渡至早期步骤处理简单任务 使CTM能够根据数据集中各样本点的固有难度自适应调整计算强度 具体操作如下公式所示：\n$$ \\begin{matrix} t_{1}=argmin(\\mathcal{L})\\\\ t_{2}=argmax(C)\\\\ L=\\frac{\\mathcal{L}^{t_{1}} + \\mathcal{L}^{t_{2}}}{2} \\end{matrix} $$然后使用随机梯度下降算法优化模型参数。整个算法流程到这里就结束了。\n然后作者又强调了一下这模型架构的优越性：\n\u0026ldquo;将时序作为 CTM 的基本功能要素引入，具有诸多有益特性。其中尤为关键的是，我们能够在不限制内部时钟周期使用数量的情况下训练 CTM。这种看似微妙的自由度实则意义深远，它使得 CTM 能够为不同数据点分配可变的计算量。这种自适应/动态计算理念与现代测试时计算范式(Test time Scaling)相契合，其区别在于：这一备受推崇的建模特性是 CTM 的自然衍生结果，而非事后施加的约束或学习过程中的限制条件。\u0026rdquo;\n小结 # 其实论文读到这里，基本已经能够理解作者想要表达的含义了。但是某一些具体的算法细节上还需要更进一步琢磨一下🤔\n内部时间维度 # 论文中貌似使用了两种不同的称谓来指代\u0026quot;内部时间维度\u0026quot;这个概念：在概念提出的章节，也就是第一节，使用的是\u0026quot;内部时间维度\u0026quot;；以及损失函数的章节，也就是最后一节，使用的是\u0026quot;内部思考维度\u0026quot;🤔\n这似乎表示了本文中的\u0026quot;内部时间维度\u0026quot;与 RNN 中的维度并不相同，尽管非常非常相似。但具体的区别点如何理解？🤔\n先鸽了，还要期末考试😢\n突触模型 # ","date":"2025-05-14","externalUrl":null,"permalink":"/blog/ctm-note/","section":"Blogs","summary":"\u003cp\u003e\n\n\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  一个新型的人脑启发式架构，在现有时序无关的神经元模型的基础上引入了\u0026quot;时序\u0026quot;概念，涌现出一系列类似人脑的现象\n\u003c/div\u003e\n\u003c/p\u003e","title":"CTM读文笔记","type":"blog"},{"content":" 梳理和总结一下关于大模型记忆的想法 前言 # 思考来源于一个在 AI 辅助编程中经常碰到的问题：每次都要从头开始理解我的代码仓库。\n目前 AI 辅助编程工具会提供大量的基础信息供 AI 迅速熟悉代码项目，然后利用各种函数工具读取项目代码、目录层级、编辑文件内容等等。在一轮交互过程中，AI 模型会完成\u0026quot;从零开始的\u0026quot;项目熟悉过程：当你发出指令让它解决某个具体的问题时，AI 会逐步探索你的代码仓库，了解相关细节然后进行相应的更改。这看起来还不错。\n然而当你开启新的一轮对话后，AI 完全忘记了自己上一次进行了什么更改，也完全忘记了你的代码仓库有哪些值得\u0026quot;记住\u0026quot;的细节，又会进行新的一轮代码仓库的探索和熟悉过程。\n非常明显的问题如下：\n浪费算力资源：反复探索仓库，无法在利用在历史探索过程中获得的有用的信息 难以处理复杂的项目：每次都需要从头开始熟悉代码仓库，有限的探索过程导致对于仓库的理解不透彻，写出来的代码没有连贯性 但是类似的问题并不只存在于 AI 辅助编程这个领域，大模型的\u0026quot;7秒记忆\u0026quot;属性在多个商业领域限制了大模型技术的落地：\n代码开发：如上，不能形成连贯的项目理解 智慧教育：难以对学生形成一个连贯的指导 情感陪伴：难以形成连贯的用户画像 这些问题总结下来其实就只有一条：现有大模型做不到对于复杂事物连贯的、准确的、动态调整的理解。\n反观人类的表现：企业员工刚开始或许不能理解项目的核心逻辑和重要细节，但是在长时间的开发过程中会对项目代码越来越熟悉，甚至能够将自己的独特理解应用在代码开发中；人类教师能够依据自身经验逐步探索学生的特点，因材施教；你的好朋友不会忘记你昨天才分享的旅游体会，也不会忘记你的性格特点。\n这也是当前大模型技术难以落地的重要原因：尽管大模型吞噬了整个互联网上的文本信息，甚至还在向图像、视频等多模态信息扩张，但是对于特定工程项目中难以用文本一次性传递的信息（项目理念、技术栈选型），没有有效的\u0026quot;经验累积\u0026quot;途径，大模型能力再强也难以有效处理。\n现状分析 # 首先概括分析当前大模型评测的侧重点，说明当前大模型的评测侧重于孤立任务而忽视了连贯任务；然后分析当前典型的交互模式，说明当前交互模式缺乏有效而连贯的经验积累。\n大模型评测 # 大模型的基准测试实在是多而杂。最近 Qwen3 上新发布，因此这里直接偷个懒，使用 Qwen3 发布的跑分表中的基准测试来举例子。\nArenaHard # 官方 Github 链接：ArenaHard；在线 demo：Arena-Hard-Auto Benchmark Viewer\nArenaHard 是一种基于模型间对战来进行评分的基准测试。测试集基于大模型竞技场（Chatbot Arena）收集的 20 万个真实用户查询，从中筛选出 500 个高质量提示词作为测试集。\n将测试集中的每一个测试都发送给待测模型，获取相应的回复结果，基准模型（GPT‑4‑0314）的生成结果官方已经预先生成。然后使用另外的大模型作为裁判，对这两个模型的回复进行评判。最后收集到模型的对战胜负表做进一步的数据处理，然后就可以计算出一个上限为 100 的分数。这个分数意味着\u0026quot;在 500 条高难指令上，裁判模型预计你能打败 GPT‑4‑0314 的概率\u0026quot;\n该基准测试已经发布了 2.0 版本，难度较之前大幅提升，在难提示词和风格控制测试中最新的跑分结果如下（截至 2025-05-03）：\nModel Scores (%) CI (%) 0 o3-2025-04-16 85.9 (-0.8 / +0.9) 1 o4-mini-2025-04-16-high 79.1 (-1.4 / +1.2) 2 gemini-2.5 79.0 (-2.1 / +1.8) 3 o4-mini-2025-04-16 74.6 (-1.8 / +1.6) 4 gemini-2.5-flash 68.6 (-1.6 / +1.6) 5 o3-mini-2025-01-31-high 66.1 (-1.5 / +2.1) 6 o1-2024-12-17-high 61.0 (-2.0 / +2.1) 7 claude-3-7-sonnet-20250219-thinking-16k 59.8 (-2.0 / +1.8) 8 Qwen3-235B-A22B 58.4 (-1.9 / +2.1) 9 deepseek-r1 58.0 (-2.2 / +2.0) 10 o1-2024-12-17 55.9 (-2.2 / +1.8) 11 gpt-4.5-preview 50.0 (-1.9 / +2.0) 12 o3-mini-2025-01-31 50.0 (-0.0 / +0.0) 13 gpt-4.1 50.0 (-1.9 / +1.7) 14 gpt-4.1-mini 46.9 (-2.4 / +2.1) 15 Qwen3-32B 44.5 (-2.2 / +2.1) 16 QwQ-32B 43.5 (-2.5 / +2.1) 17 Qwen3-30B-A3B 33.9 (-1.6 / +1.5) 18 claude-3-5-sonnet-20241022 33.0 (-2.3 / +1.8) 19 s1.1-32B 22.3 (-1.7 / +1.5) 20 llama4-maverick-instruct-basic 17.2 (-1.5 / +1.2) 21 Athene-V2-Chat 16.4 (-1.4 / +1.4) 22 gemma-3-27b-it 15.0 (-1.4 / +1.0) 23 Qwen3-4B 15.0 (-1.1 / +1.5) 24 gpt-4.1-nano 13.7 (-1.1 / +1.0) 25 Llama-3.1-Nemotron-70B-Instruct-HF 10.3 (-0.8 / +1.0) 26 Qwen2.5-72B-Instruct 10.1 (-0.9 / +1.3) 27 OpenThinker2-32B 3.2 (-0.3 / +0.3) 从上面的介绍中就可以看出：ArenaHard 只测试了模型解决孤立问题的能力。\nAIME # AIME 即美国数学邀请赛，严格意义上来说不算是专门的大模型基准测试，但确实能够反映模型的数学推理能力。\n整个比赛包含 15 道题，答案都是数值，没有步骤分。最终得出的跑分结果也就是正确率，可能会有多次测试取平均值或者最高值，但并没有统一的标准。\n很明显，AIME 也只测试了大模型一次性解决孤立问题的能力。\n典型交互模式 # 现在的大模型有记忆能力吗？有，但只是短期记忆。目前人类与大模型的交互方式概括如下：\n人类提供任务的背景信息 大模型依据背景信息尝试完成这个任务 大模型在执行任务的过程中不断与人类进行交互（短期记忆） 模型完成任务 所谓\u0026quot;短期\u0026quot;记忆就体现在\u0026quot;短\u0026quot;：最长不超过大模型的上下文窗口的长度。而具体的实现方法就是：直接把用户和模型的交互历史全部放入窗口之中。\n尽管现有大模型的上下文窗口越来越长，甚至能够达到 200 万 token 的上下文（1.5 部红楼梦），但是这并不意味着我们能把所有的交互信息都塞进窗口之中还期望模型能够低成本、高准确地生成内容😢 小结 # 目前的评测重点和交互模式对于孤立的任务非常适用，但是事实上我们需要完成的任务都是在一个大目标框架下的\u0026quot;子任务\u0026quot;，这些\u0026quot;子任务\u0026quot;之间彼此关联，相互牵制。\n一个有趣的现象是：当我们尝试去解决其中一个子任务后，解决其他的任务会更加轻松。原因就是：在探索如何解决别的子任务的时候，有部分探索结果对于解决别的子任务有增益，因为这些子任务都归属于同一个目标。\n因此现在改进的方向也很明确了：为大模型引入一个在线学习的长期记忆模块，使大模型能够从历史探索中积累经验。\n相关工作 # Titans # Titans 架构是谷歌最新推出的对于 Transformer 架构的改进架构，提出了\u0026quot;Test-time Memory\u0026quot;的概念，旨在扩展模型的上下文长度的同时提供更加准确的注意力机制。引入了一个能够在测试时动态更新的参数网络，能够将长期的记忆信息保存其中，提升注意力机制的性能。\nKBLaM # KBLaM\nTTRL # TTRL 算法能够在测试时利用强化学习来更新模型的权重参数，实现了模型参数的实时动态更新\nrStar # rStar 使用 MCTS 来探索生成高质量推理路径的框架。有别于需要一个强模型作为指导的模型蒸馏方法，该框架借鉴了同伴之间相互验证学习的方法，利用投票机制获得一个模拟的\u0026quot;正确答案\u0026quot;来指导生成高质量路径。\nTokenformer # Tokenformer 框架秉持着\u0026quot;万物皆可tokenize\u0026quot;的理念，\nSD-LoRA # SD-LoRA\nDifferential Transformer # Differential Transformer 改进了传统 Transformer 架构中的注意力机制，提出了\u0026quot;差分注意力机制\u0026quot;的概念。与传统的softmax注意力不同，Diff Transformer 将查询（query）和键（key）向量分为两组，分别计算两个独立的softmax注意力图，然后通过减法操作消除噪音。这一机制类似于电子工程中的差分放大器，通过两个信号的差值来消除共模噪音。\n思路梳理 # 大模型记忆 # 当我们断网本地运行一个大模型时，我们向其提问：相对论是谁提出的？它能够告诉我们：相对论是爱因斯坦提出的。这其实就说明了在模型的参数中已经存储了相关的事实信息，也就是所谓的\u0026quot;记忆\u0026quot;。\n那么这部分主要回答：Transformer 的记忆存储在哪里？\n解构Transformer # 对于 Transformer 的可解释性研究一直都在进行之中，本文根据 DeepMind 的相关研究和 Anthropic 的相关研究来对 Transformer 的结构进行解读。\n概括来讲：整个过程中的残差连接被视作一个\u0026quot;数据总线\u0026quot;，贯穿整个模型的计算过程；将 Attention Layer 和 MLP Layer 视作信息的读写头，在数据总线上进行数据的读写。\nEmbedding # Embedding 过程是 Transformer 处理流程的第一步：\nTokenize：对文本进行词元化处理 Embedding：将词元转化为向量并写入位置编码 这一步直观来讲就是：把一句话变成了一簇向量。在这个过程利用了嵌入矩阵将词元转化为了合理的数值向量。也就是说嵌入矩阵中就存储了一些事实信息，包括不同实体之间的关系、不同词元之间的差距等等，但是这些信息是建立在大量文本之上的平均值，无法表示动态的语义。\n举个经典的例子：\u0026ldquo;bank\u0026quot;一词既有\u0026quot;河岸\u0026quot;的意思，又有\u0026quot;银行\u0026quot;的意思，但是嵌入矩阵描述的是这两个意思的某种\u0026quot;平均值\u0026rdquo;。\nMulti-head Attention # 正如上文所说，单纯的嵌入矩阵无法描述基于上下文的、动态的语义，因此多头注意力机制被引入，用于构建更加精确的词向量。\n一个形象的描述就是：通过 Embedding 之后产生了一簇向量，而这些向量之间会相互影响，而多头注意力层中的参数就建模了这种复杂的相互影响。按照电路的解释框架，也就是说 Attention Layer 计算出了这一簇向量之间的\u0026quot;相互影响增量\u0026quot;，然后将这个增量写回\u0026quot;数据总线\u0026quot;之中。\nMLP # DeepMind 的研究表明，事实性的信息大部分都存储在 MLP 层中。在这里将 MLP 层中的操作分解为两个步骤：\n事实匹配 计算需要注入的事实 经过多头注意力处理的向量都偏移到了当前语境中的正确位置，这些向量中已经包含了大量叠加在一起的复杂信息（大量明确的语义通过加法融合在了一个向量之中）。而扩展矩阵的作用就类似于一个检查表：每一行都是一个检查项目（这些项目的具体含义同样是高度叠加的），检查项目和词向量通过点积得到\u0026quot;匹配分数\u0026quot;，然后通过非线性截断函数（ReLU）剔除不相关的匹配。这一步就是\u0026quot;事实匹配\u0026quot;过程。\n例如，使用扩展矩阵去检测\u0026quot;相对论\u0026quot;这个词元时，某一行可能会同时检测：\u0026ldquo;是否是一个学术概念+是否是球类运动+是否是星系名称\u0026rdquo;。检测结果可能是相关的，也可能是不相关的，但最后都会线性叠加在一起。\n为什么可以叠加？因为向量点乘的分配律：\u0026ldquo;先叠加再匹配\u0026quot;和\u0026quot;先匹配再叠加\u0026quot;是等价的 然后投影矩阵则充当了\u0026quot;计算事实增量\u0026quot;的作用：根据匹配分数，计算原本的词向量中到底需要添加哪些事实信息，把所有需要添加的事实信息都加在一起，表示为一个事实增量向量。\n然后 MLP 层将\u0026quot;事实增量向量\u0026quot;写回残差流之中。\n堆叠 # Transformer 通过将上述结构进行反复堆叠，更深入的层提取的信息也就更加复杂而难以理解。\n需要注意的是：事实信息的注入并非发生在单独某一层的 MLP 中，甚至不单独发生在某一个 Transformer Block 之中，而是在整个网络之中不断迭代，逐步产生更加清晰明确的影响。\n这种复杂的事实信息注入机制给可解释工作带来了不小的困难，也让人们难以精确控制大模型内部的信息流动。但是这个过程恰恰体现了将事实信息存储在神经网络之中的优势：对于某个复杂的信息，最开始这个信息能够关联大量而模糊的其他信息，然后在每层网络计算之中逐步精确，最后收敛到真正高度相关的信息。\n这也是 Attention Layer 和 MLP Layer 交替出现的一个理由：事实信息在 MLP Layer 注入之后马上使用 Attention Layer 来进行裁切，去掉较弱的关联，放大较强的关联，避免大量冗杂信息传递到下一个 MLP Layer 中激发更加混乱的关联 时间编码 # Transformer 本身无法感知词元之间的顺序，真正表征词元之间位置循序的工作其实是\u0026quot;位置嵌入\u0026quot;。目前为了更加高效地将位置信息嵌入词元之中，产生了多种不同的方法：\n正余弦嵌入：在 Transformer 原论文中就已经出现，是一种绝对位置编码，直接将 PE 信息叠加到原始词向量之中 向量旋转嵌入：直接替换 Q、K 矩阵，把每维 Q、K 拆成偶数维对，在复平面做角度旋转 可学习的位置嵌入：类似正余弦嵌入，也是一种绝对位置编码，直接利用反向传播训练 类似地，为了适应流式的信息输入，我们也应该对信息的获取时间进行编码：十年前互联网上的信息和现在互联网上的信息应该有区别才对。并且在这个过程中，大模型还能像学习\u0026quot;词元的顺序\u0026quot;一样，隐式地学习\u0026quot;信息的先后\u0026quot;，让大模型隐式地理解\u0026quot;时间\u0026quot;这个概念。\n合适的时间编码应该有如下的特点：\n时间跨度越大，差距应该越大 应该保留时间的周期性信息 事实注入 # 上面的文字已经描述了事实性的信息是如何以模型参数的方式参与 token 的生成。然而这些信息是如何存储到参数之中的？简单来说就是利用反向传播算法调整参数，但如果我们继续追问：\n存储某一个事实信息需要什么样的训练样本？需要多少训练样本？ 已经存储进去的信息如何\u0026quot;接纳\u0026quot;新的信息？ 事实信息的存储过程是否与整个网络的训练过程不可分割？ 如果知道了上述问题的答案，那么就可以构建一个能够持续吸收事实信息的框架：只需要持续不断输入指定格式的训练样本然后实时执行反向传播即可。\n现有方法 # 这部分主要回答：现在实现\u0026quot;长期记忆\u0026quot;有哪些途径？各自有什么优缺点？\nRAG # RAG 原本是用于缓解大模型幻觉的技术，但其实质就是利用外部的信息处理模块（向量数据库），将有用的自然语言信息直接加入提示词中。\n遵循这个思路，不仅能够缓解大模型幻觉，还能够直接让模型能够完成某些特定的工作（提示词工程），当前大量的 AI 应用也都是这样实现的：\ncursor：自动添加代码仓库的背景信息和种类繁多的工具，然后依靠模型自身的能力来完成复杂的代码编写工作 Manus：提供了更加复杂的信息处理工具，利用大模型自身的超长上下文来记录所有收集到的信息来完成任务 MCP：虽然只是一个工具调用协议，但是其底层还是一个提示词工程 \u0026ldquo;使用 RAG 来实现长期记忆\u0026quot;这个方向已经产生了不少可观的成果：\nmem0：基于向量数据库的大模型记忆系统，让大模型能够从对话中记住用户的偏好 graphiti：基于向量化的图数据库的记忆系统，为大模型构建实时的知识图谱，能够存储大量过去的事实性信息并准确提取出相关记忆 memobase：基于文件存储同时结合向量数据库的记忆系统，将用户的偏好等信息写入用户画像文件中并不断更新 这种方式的优点非常明显：\n简单便捷：人类自身非常熟悉自然语言，因此使用自然语言驱动程序运行相对而言也非常容易理解 信息可控：通过显示编程的方式将信息整合成一个超长但是逻辑严密的提示词，能够方便地控制复杂信息。 大模型技术的应用：大模型本身就是顶尖的语言处理技术，能够参与到背景信息组织的各个环节，提升复杂信息的处理能力 使用 RAG 的缺点也是存在的：\n上下文窗口限制：大模型的注意力层只能支持有限的上下文，过长的上下文将会自动截断 注意力发散：在上下文窗口中填入过多的信息将会导致模型的注意力机制性能下降，难以捕捉真正重要的信息 表达能力受限：过于复杂的信息难以使用自然语言表达，即便强行表达也会缺失关键信息，导致大模型出现理解偏差，例如，一个复杂的软件项目的开发理念，如果不在实践过程中加以体会，使用自然语言描述出来的理念就是一堆空话 记忆维护困难：即便拥有大模型技术的加持，记忆的更新维护和提取仍然是一个棘手的问题，响应速度、准确率和成本的平衡难以把控 微调 # 需要去看看微调方面的论文，特别是\u0026quot;高效微调\u0026quot;方面的文章，看看能不能增强其在线学习能力🤔如果可能的话还需要去看看增量学习方面的文章。\n暂时先鸽了😢还要复习期末考试\n网络参数 # 这方面的工作目前非常稀少，尽管 OpenAI 最新推出了记忆功能，但并没有透露具体的实现方法，网上的讨论度也不高。这里主要概括一下 Titans 架构的实现方法。\n早期想法 # 这里写目前的想法，都是一些非常早期的想法。\n思考一个问题：大模型的能力是从何而来的？来源于海量的互联网文本。\n大模型在海量的文本上训练，利用反向传播算法将文本之间的相互影响和事实信息全部都压缩到了神经网络的参数之中，对语言建模的同时也完成了对于语言所代表的抽象概念的建模。当然这个过程非常的缓慢，需要大量的算力支撑。\n完成如此大量的知识压缩之后，如何处理新的信息？这是一个尚待解决的问题，但并非一个不可解决的问题：人类自身的知识就是由少到多逐步积累而成的，人脑必须处理并存储不断输入的新信息，将新信息与旧有信息进行融合。\n引用 # Arena-Hard：开源高质量大模型评估基准 Titans KBLaM TTRL rStar Tokenformer SD-LoRA Differential Transformer A Mathematical Framework for Transformer Circuits 直观解释注意力机制，Transformer的核心 Fact Finding: Attempting to Reverse-Engineer Factual Recall on the Neuron Level (Post 1) Fact Finding: Simplifying the Circuit (Post 2) 直观解释大语言模型如何储存事实 Diff Transformer：让注意力机制更智能，消除噪音，提升大语言模型性能-知乎 ","date":"2025-05-04","externalUrl":null,"permalink":"/blog/llm-memory/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  梳理和总结一下关于大模型记忆的想法\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e思考来源于一个在 AI 辅助编程中经常碰到的问题：每次都要从头开始理解我的代码仓库。\u003c/p\u003e","title":"关于大模型记忆","type":"blog"},{"content":" 总结记录一下折腾Ubuntu系统的过程，以备不时之需 前言 # Ubuntu 作为一个流行的 Linux 发行版本，对比其他 Linux 发行版，有较好的生态支持。最主要的体现就是：当你遇到问题的时候 Ubuntu 能够搜到的教程更多。\n这篇文章主要针对带有 GUI 的个人版 Ubuntu 系统，服务器专用的 Ubuntu 系统操作取决于你的实际业务，云服务器搭建这篇文章可以作为一个参考。\nUbuntu安装 # 非常久远之前就安装好了，故不做记录了。如有需要，请自行搜索“移动硬盘安装 Ubuntu”等关键词。这里放一个较新的链接：移动硬盘安装Ubuntu\n安装过程已经不可考究了，现状就是我将 Ubuntu 系统安装在一个移动硬盘中，随插随用。\n使用的时候就可以在开机之前把硬盘插上，点击电源按钮之后快速点击某个按键进入 BIOS 引导界面，把优先级提升到最高然后保存推出就可以正常进入 Ubuntu 系统了。\n不想使用的时候直接不插上硬盘就可以了，正常开机，不需要任何的操作就可以直接进入 Windows 系统，非常地方便。\n界面美化 # 我个人比较喜欢苹果风格的界面，因此特地找了一款苹果风格的主题：WhiteSur\n安装过程非常简单：\ngit clone https://github.com/vinceliuice/WhiteSur-gtk-theme.git --depth=1 cd WhiteSur-gtk-theme ./install.sh # 运行安装脚本 具体的配置操作请见 Github 官网上的说明\n至于如何升级，官方没有说明，估计是默认用户都知道：\ngit pull # 拉取最新的代码 ./install.sh # 重新运行安装脚本即可 Fcitx 5 # 主要参考：在 Ubuntu 安装配置 Fcitx 5 中文输入法；之前有考虑过使用搜狗输入法，但是看到官方给的安装流程就头大，而且也需要安装 Fcitx 5，所以不如直接用 Fcitx5 了\n其实一开始我是拒绝 Fcitx 的🥲因为它的界面实在是\u0026quot;朴素\u0026quot;得令人难以接受，相信上面那篇博客的作者应该和我深有同感👆\n使用Windows上的字体 # 思路：将 Windows 中的字体文件拷贝到 Ubuntu 专用的字体文件夹中，然后给予适当的权限，然后刷新 Ubuntu 的字体缓存，加载新的字体。\n# Windows上的字体文件夹：C:/Windows/Fonts sudo cp /mnt/C/Windows/Fonts/LXGWWenKai-Regular.ttf /usr/share/fonts/custom/LXGWWenKai-Regular.ttf # 提高权限 sudo chmod u+rwx /usr/share/fonts/custom/* # 进入字体文件夹 cd /usr/share/fonts/custom/ # 建立字体缓存 sudo mkfontscale # 刷新缓存 sudo fc-cache -fv 当然，你也可以直接从网上下一个新的 .ttf 文件然后再复制到指定文件夹中。而且如果你使用的是带有 GUI 界面的 Ubuntu 系统，下载文件之后你可以直接双击字体文件来安装🥰\n字体可能会重复安装，系统不会检查某个字体是否重复安装；如果安装重复了请自行去相关文件夹中查找并手动删除🥲Ubuntu 中字体工具可以查看所有字体信息 挂载硬盘 # 由于我的 Ubuntu 系统安装在移动硬盘上，因此这里主要解决的问题是：如何在 Ubuntu 上访问 Winodws 中的盘区。因此不涉及对于分区的具体处理，如果需要对分区进行格式化等等操作，详见：如何在Ubuntu系统中进行磁盘的分区与挂载\n# 查看磁盘及其分区，sudo提权不可省略 sudo fdisk -l # 创建挂载位点，其实就是建一个文件夹 # mnt中的子文件夹之所以取名为E是，因为这里准备挂载E盘 sudo mkdir /mnt/E # 直接挂载新分区 sudo mount /dev/vdb /mnt/E # 设置开机自动挂载 # 查看分区的UUID sudo blkid # 编辑特定文件 vim /etc/fstab # 在文件末尾追加 UUID=xxxxxxxx /mnt/E ntfs defaults 0 2 上面的 UUID 请替换为 blkid 命令获取的内容，ntfs 处也替换为相应的文件系统类型（常见的如 ntfs ext4） defaults：这是一个组合选项，包含一组默认挂载选项，如rw（读写）、relatime（减少inode访问时间更新次数）等 0和2：这些值分别控制是否需要备份和文件系统检查顺序。通常第一个值为 0（不备份），第二个值为1或2（1用于根文件系统，其他文件系统用2） 测试方法：\n# 运行后如果没有报错则说明配置正确 sudo mount -a 创建快捷方式 # 常见的一个操作：我想在桌面放一个常用文件夹的快速链接，方便快速进入对应文件夹\n# 在Desktop文件夹中放置一个指向/target/dir文件夹的链接 # 请替换为你的目标文件夹 ln -s /target/dir ~/桌面 # 测试，如果能cd进去那么就没问题 cd ~/桌面/dir 配置Git # Linux 的一大特色就是极致的简洁，因此使用命令行来操纵 Git 是 Linux 用户的首选😃Ubuntu 自带 Git 所以说不用自行安装了，如果想要升级的话见下：\ngit --version # 查看git版本 sudo add-apt-repository ppa:git-core/ppa # 添加官方源 sudo apt update \u0026amp;\u0026amp; sudo apt upgrade # 如果能的话则执行更新 为 GitHub 设置 ssh 免密配置，当然你也可以直接使用 HTTPS，但是缺点就是每次都要输入密码。而且随着 GitHub 的安全措施升级，密码也不见得是你的账号密码，而是专门的 token🥲\n如此麻烦的操作是 Linux 上无法忍受的，我宁愿进行繁琐的配置，但是我一定不要每次都输入那一长串 token\n这里主要参考：设置 Git 默认推送不需要输入账号和密码【Ubuntu、SSH】\ngit config --global user.name \u0026#39;xx\u0026#39; # 配置全局用户名 git config --global user.email \u0026#39;xxx@qq.com\u0026#39; # 配置全局邮箱账号 # 生成shh密钥对，然后我选择一路回车到底 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; # 启动 SSH 代理并将私钥加载到代理 eval \u0026#34;$(ssh-agent -s)\u0026#34; ssh-add ~/.ssh/id_rsa # 查看并复制公钥内容 cat ~/.ssh/id_rsa.pub # 在GitHub上添加这个新的ssh密钥就行 # 将现有https链接的仓库改为ssh链接 git remote rm origin git remote add origin git@github.com:username/repository.git 安装管理软件 # 在 Ubuntu 上安装软件的方式大致分为以下几种;\n通过自带的 snap 安装 通过 apt 安装 通过 deb 压缩包安装 通过 curl 安装 不同的安装方式有不同的管理方案，其中通过 curl 安装的管理最为不便，其他的都可以通过相应的包管理工具轻松管理\nsnap # 直接打开 snap 商店就可以直接看到，轻松便捷，但是其中的软件包往往较为落后\napt # # 软件源的相关操作在桌面版中可以在\u0026#34;软件与更新\u0026#34;中进行图形化操作 # 添加软件源 sudo add-apt-repository ppa:libreoffice/ppa \u0026amp;\u0026amp; sudo apt update # 移除软件源 sudo add-apt-repository --remove ppa:libreoffice/ppa # 安装软件 sudo apt install xxx # 升级软件包 sudo apt update # 同步远程仓库的软件包信息，但不会实际升级任何软件 apt list --upgradable # 查看可升级的软件包 # 升级所有可用的包，但不会处理依赖关系变更（如删除旧包或安装新依赖） sudo apt upgrade sudo apt full-upgrade # 完全升级 sudo do-release-upgrade # 跨ubuntu大版本升级 # 查看软件包 sudo apt-cache search wps # 搜索所有包含wps的软件包及其描述信息 sudo apt-cache pkgnames | grep -i wps # 查看包含关键字wps的软件包名字 # 移除软件包 sudo apt remove xxx sudo apt autoremove # 清理残留 deb # 从浏览器上下载 deb 压缩包之后，直接双击即可直接安装。其内部执行的命令其实就是 apt 安装，因此管理方式也是与 apt 相同的。\n# 通过双击安装 # 通过apt卸载 sudo apt remove xxx sudo apt autoremove # 清理残留 AppImage # AppImage 是一种用于 Linux 系统的便携式软件打包格式，旨在简化应用程序的分发和运行。它的核心思想是“一个应用 = 一个文件”，用户无需安装或管理员权限即可直接运行应用程序。\n在较新的 Ubuntu 版本中，直接运行该文件会出现报错，需要额外安装 libfuse2，使用如下命令即可：\nsudo apt install libfuse2 然后对软件包提权：\nchmod +x file_name.AppImage 然后双击软件包就能启动了😃\n千万不要直接安装 fuse ，这会自动卸载 fuse3，导致新版本的 Ubuntu 文件系统崩溃！如果不小心安装了，请移除 fuse，然后查看 apt 的操作日志，将自动卸载的包手动重新安装回来！ 如果你想卸载软件的话，也非常方便：直接把软件包删除就行了。当然，如果你和我一样有\u0026quot;洁癖\u0026quot;，可以去检查下面的这些目录，彻底清除残留：\nls ~/.config -a # 查看配置文件 ls ~/.local/share -a # 查看共享配置文件 ls ~/.cache -a # 查看缓存 du -sh ~/.cache/* | sort -h -r # 查看.cache目录下各个文件夹的磁盘占用 curl # 通过 curl 命令直接从目标网址下载安装脚本，然后执行这个脚本。通过 curl 安装的软件可管理性较差，原因在于：实际的安装过程是通过脚本执行的，这个过程难以监控\n# 以zed编辑器的安装为例 curl -f https://zed.dev/install.sh | sh # 如果想要卸载，一般都是难以卸载干净的 # 首先获取安装脚本文件 curl -f https://zed.dev/install.sh -o install.sh # 把这个脚本文件丢给AI解析一下 # 然后按照AI的指令手动进行卸载 大版本更新 # 进行大版本的更新对于服务器 OS 来说是完全没有必要的，因为相关套件一般都还没有跟上，追逐\u0026quot;最新版本\u0026quot;并不明智。但是对于桌面版用户来说还是很有用的，毕竟更新之后就能体验最新的系统特性，说白了就是好玩儿🤓\n这部分主要参考微信公众号：如何从 Ubuntu 24.04 升级到 Ubuntu 25.04\n数据备份 # 这一步是非常有必要的，虽然说可能会占用好几十个 G 的硬盘空间，但毕竟大版本更新还是一个有风险的操作，不怕一万就怕万一😅升级成功后再删除备份，释放空间也行啊\n# 安装备份工具 sudo apt install deja-dup # 直接运行 deja-dup 更新软件包 # 确保系统处于最新状态可以最大程度上减少兼容性问题，逐条运行下面命令即可：\nsudo apt update sudo apt full-upgrade sudo apt autoremove sudo apt autoclean sudo reboot # 重启系统 版本更新 # 逻辑很直接：把旧版本相关软件源指向新版本对应的软件源就行，下面罗列一些相关文件，如有修改就需要改这些文件：\n升级策略文件：/etc/update-manager/release-upgrades 软件源配置文件：/etc/apt/sources.list.d/ubuntu.sources 如果你想从 LTS 版本升级为非 LTS 版本，那么就需要更改策略文件。策略文件中其实也只有一行，改成下面的样子就行：\nPrompt=normal 接下来修改软件源配置文件，运行如下命令：\nsudo sed -i \u0026#39;s/noble/oracular/g\u0026#39; /etc/apt/sources.list.d/ubuntu.sources 文件修改完成之后：\n# 刷新索引并执行完整更新，包括内核、驱动和所有软件包 sudo apt update \u0026amp;\u0026amp; sudo apt full-upgrade -y 其中的 -y 选项是\u0026quot;自动确认\u0026quot;的意思，如果你想手动输入 yes 的话可以不加😃我反正不想 升级完成后：\nsudo reboot # 重启系统应用更改 lsb_release -a # 验证系统版本 Office套件 # 众所周知，Microsoft Office 是没法直接在 Linux 上直接运行的😅但是查看和编辑 doc 文档又是无法避免的。\n因此这里推荐一个 Linux 上的 Office 平替：LibreOffice，安装方式如下：\nsudo add-apt-repository ppa:libreoffice/ppa sudo apt update sudo apt install libreoffice 在安装 LibreOffice 之前也尝试过使用 WPS 来编辑 Office 文件，但是不知为何总是会引起系统报错，索性就直接弃用了\n如果你是 Office 的深度用户，换了软件就浑身难受，那么你可以尝试一下 Wine，一个能在 Linux 上跑 Winodws 程序的神奇工具 存储清理 # # 清理孤立依赖包 sudo apt autoremove # 清理apt缓存 sudo du -sh /var/cache/apt # 查看apt缓存大小 sudo apt autoclean # 自动清理 sudo apt clean # 完全清理 # 清理系统日志 journalctl --disk-usage # 查看系统日志代大小 sudo journalctl --vacuum-time=3d # 清除三天前的日志 # 清理.cache du -sh ~/.cache/* | sort -h -r # 查看缓存文件大小 rm -r folder_name # 直接删除即可 # 清理snap旧版本 snap list --all # 查看所有snap包 # 罗列出所有被禁用的包（下面是一行命令） echo -e \u0026#34;\\033[1m已禁用的 Snap 包及其占用空间:\\033[0m\u0026#34; \u0026amp;\u0026amp; snap list --all | awk \u0026#39;/disabled|已禁用/{print $1}\u0026#39; | while read -r pkg; do size=$(snap info \u0026#34;$pkg\u0026#34; | awk \u0026#39;/installed:/ {print $4}\u0026#39;); printf \u0026#34;%-30s %10s\\n\u0026#34; \u0026#34;$pkg\u0026#34; \u0026#34;$size\u0026#34;; done | sort -k2 -h # 移除所有被禁用的snap包（下面是一行命令） snap list --all | awk \u0026#39;/disabled|已禁用/{print $1, $3}\u0026#39; | while read snapname revision; do sudo snap remove \u0026#34;$snapname\u0026#34; --revision=\u0026#34;$revision\u0026#34;; done # 清理内核 sudo dpkg --list | grep linux-image # 列出所有内核 sudo apt autoremove --purge # 自动清除不需要的内核 其他 # 这里包含了一些简单而常用的命令\n系统控制 # 立刻关机：shutdown now\n立即重启：sudo reboot\n解压 # 命令根据你需要解压的文件格式而变动\n# 解压zip文件 unzip file.zip -d /target/directory # 解压.tar文件 tar -xvf file.tar # 解压.tar.gz文件 tar -xzvf file.tar.gz 引用文献 # 如何在Ubuntu系统中进行磁盘的分区与挂载 LibreOffice Suite - 适用于 Linux 的 Microsoft Office 套件的最佳替代方案 在 Ubuntu 安装配置 Fcitx 5 中文输入法 设置 Git 默认推送不需要输入账号和密码【Ubuntu、SSH】 ","date":"2025-05-01","externalUrl":null,"permalink":"/blog/ubuntu-note/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  总结记录一下折腾Ubuntu系统的过程，以备不时之需\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eUbuntu 作为一个流行的 Linux 发行版本，对比其他 Linux 发行版，有较好的生态支持。最主要的体现就是：当你遇到问题的时候 Ubuntu 能够搜到的教程更多。\u003c/p\u003e","title":"Ubuntu折腾札记","type":"blog"},{"content":" 关键词：互推理；小模型；推理能力提升 研究背景 # 现有工作 # 以下内容由 AI 生成，快速解释 RAP 是什么。\n研究基础是一种名为 RAP（Reasoning via Planning）的框架，旨在通过将语言模型（LLM）同时作为世界模型和推理代理，并结合蒙特卡洛树搜索（MCTS）算法进行策略性探索，从而提升模型在复杂任务中的推理能力。\n问题背景：\n当前的大型语言模型（LLM）在推理任务中存在局限性，主要原因是缺乏对环境的心理表征（世界模型），无法有效预测动作的结果和长期影响。 此外，LLM 缺乏奖励机制来评估推理路径，也无法平衡探索和利用，导致推理效率低下。 RAP 框架：\n语言模型作为世界模型：通过自然语言定义状态和动作，将推理过程建模为马尔可夫决策过程（MDP），并利用 LLM 预测每个动作的结果。 奖励设计：使用动作的对数概率、置信度以及 LLM 自身的评估结果作为奖励，引导推理走向理想状态。 蒙特卡洛树搜索（MCTS）：通过 MCTS 迭代构建搜索树，平衡探索和利用，最终选择高奖励的推理路径。 不足之处 # LLM 难以有效探索解空间，常常会产生低质量的推理路径 LLM 难以准确评估推理路径质量的高低 上述问题在小模型中更加突出 方法概述 # 拟人推理 # 推理路径仍然依赖 MCTS 来生成，但是提供了更丰富的模拟人类思考推理流程的动作：分解和搜索某一个推理步、提出子问题、问题转化等等\n路径评估 # 使用相互一致性原则判定路径质量，即引入另外一个能力相当的小模型来作为“同伴”，以此判定推理路径的质量，具体流程如下：\n框架会给予“同伴”小模型一些局部推理路径作为提示，然后让这个小模型补全推理路径 如果 MCTS 生成的路径与“同伴”小模型补全的路径一致，那么就认为这个推理路径质量高，可以作为候选路径 使用能力相当的小模型，避免对大模型进行蒸馏；使用“同伴模型”对路径进行评估而非直接指导路径生成；判断\u0026quot;路径一致\u0026quot;主要依赖最终结果 具体方法论 # 符号说明表格：\n符号 含义 \\(x\\) 目标问题 \\(M\\) 目标小模型 \\(T\\) 小模型使用 MCTS 生成的搜索树 \\(s\\) 推理中间步 \\(t\\) 候选路径，\\(T\\) 中的一条完整推理路径 \\(ans\\) \\(M\\) 解决 \\(x\\) 的最终推理路径 \\(Score\\) 推理路径评价函数 \\(a\\) 从动作空间中采样得到的一个动作 \\(s_{d}\\) 终止推理步，包含问题的答案 \\(\\hat{M}\\) \u0026ldquo;同伴\u0026quot;小模型 \\(T_{validate}\\) 经过路径评估函数剪枝后的 \\(T\\) \\(Estimate\\) 路径评估函数 问题规范化 # 把“小模型解决推理问题”这个抽象的自然语言描述的过程形式化：\n$$ t=x\\oplus s_1 \\oplus s_2 \\oplus ...\\oplus s_d $$$$ T=\\left \\{ t^1, t^2, ..., t^n \\right \\} $$$$ T_{validate}=Estimate(T) $$$$ ans = max(Score(T_{validate})) $$ 拟人推理 # 动作空间 # 一步思考：给予现有推理路径，让模型产生下一步的推理 快速思考：直接让模型补全所有的推理步，直到产生最终结果 子问题+回答：让模型提出一个子问题并回答这个子问题 子问题重回答：上一步中产生的答案可能不准确，因此提供一个额外的动作选项，重新回答子问题 问题重述：让模型重新整理问题中的条件 注意，动作4 只能发生在动作3 之后，动作5 只能发生在问题本身(根节点)之后 奖励函数 # 借鉴了 AlphaGo，将中间步的评价(奖励)设置为其对于正确的结果的贡献，具体实现如下：\n初始化 \\(Q(s_{i},a_{i})=0\\)；随机产生下一步，直到遇到终止结点 \\(s_{d}\\) 使用一致性投票计算 \\(Q(s_{d},a_{d})\\)，也是终止结点的置信度分数 反向传播：\\(Q(s_{i},a_{i})=Q(s_{i},a_{i})+Q(s_{d},a_{d})\\) MCTS # 大体上使用了经典的 MCTS：选择、扩展、模拟(Rollout)和反向传播；只是为了获取更加精确的奖励值，执行了多次模拟评估\n探索-开发平衡依然使用经典 UCT 公式：\n$$ UCT(s,a) = \\frac{Q(s,a)}{N(s,a)}+c\\sqrt{ \\frac{\\ln N_{parent}(s)}{N(s,a)} } $$其中 \\(N(s,a)\\) 表示某个节点被访问过的次数，\\(Q(s,a)\\) 就是可以被累计更新的奖励值，\\(c\\) 表示平衡率\n路径评估 # 对于一条推理路径 \\(t=x\\oplus s_1 \\oplus s_2 \\oplus ...\\oplus s_d\\)，随机抽取一个推理步 \\(s_{i}\\) 将 \\(s_{i}\\) 之前的推理路径 \\(t_{1}=x\\oplus s_1 \\oplus s_2 \\oplus ...\\oplus s_i\\) 作为提示词注入\u0026quot;同伴\u0026quot;小模型 \\(\\hat{M}\\) \\(\\hat{M}\\) 补全路径，产生新路径 \\(t'=x\\oplus s_1 \\oplus s_2 \\oplus ...\\oplus s_i \\oplus s_{i+1}' \\oplus \\dots \\oplus s_{d}'\\) 如果\u0026quot;路径一致\u0026quot;也就是得出的问题答案一致，那么 \\(t'\\) 就被视作候选路径 选出候选路径的过程就是 \\(T\\) 被剪枝的过程，最终产生 \\(T_{validate}\\) 最终选择 # 对于候选路径树中的每一个候选路径 \\(t=x\\oplus s_1 \\oplus s_2 \\oplus ...\\oplus s_d\\)\n$$ Score(t)=\\prod_{i=1}^{d} Q(s_{i},a) $$最后选择分数最大的那一条推理路径：\n$$ ans = max(Score(T_{validate})) $$ 其他细节 # MCTS 执行 32 次 Rollout 处理 MATH 数据集的时候 MCTS 最大深度为 8，其余情况最大深度为 5 \u0026ldquo;同伴\u0026quot;小模型的推理与目标小模型的推理可以并行执行，提高计算效率 路径评估的时候，路径截断点应该处于总路径的 \\(20\\% \\sim 80\\%\\) 之间 ","date":"2025-03-20","externalUrl":null,"permalink":"/blog/rstar-note/","section":"Blogs","summary":"\u003cp\u003e\n\n\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  关键词：互推理；小模型；推理能力提升\n\u003c/div\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e研究背景 \n    \u003cdiv id=\"%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\n\n\u003ch3 class=\"relative group\"\u003e现有工作 \n    \u003cdiv id=\"%E7%8E%B0%E6%9C%89%E5%B7%A5%E4%BD%9C\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%8E%B0%E6%9C%89%E5%B7%A5%E4%BD%9C\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e以下内容由 AI 生成，快速解释 RAP 是什么。\u003c/p\u003e","title":"rStar读文笔记","type":"blog"},{"content":" 详细记录了从零开始发布 LLM 应用的过程，主要内容关注云服务器的初始化搭建过程，持续更新中\u0026hellip; 前言 # 在发布你的 LLM 应用之前，你应该已经基本完成了：\n带有核心功能的网页前端框架 功能相对完整的后端代码仓库 这里主要记录了测试开发环境的云服务搭建过程，用于生产环境的云服务器目前还没有涉及，因此请参考别的文章，没有实践就没有发言权🫡\n方案探索 # 虽然这篇文章是\u0026quot;云服务器搭建\u0026quot;，但是我还是想记录一些\u0026quot;非云服务\u0026quot;的方案，毕竟不是所有的测试开发环境都需要一个昂贵的云服务器。如果你已经确定了要使用云服务器，那么跳转到：云服务操作流程\n下面的内容均假定你的主力生产环境是 Windows，因为我 Linux 和 MacOS 都没用过😢\n本地服务 # 大体思路 # 如果你是一个真正意义上的\u0026quot;独立\u0026quot;开发者，没有任何人需要与你进行协同开发，那么你完全不需要一个云服务器，你只需要一个 Docker 就行。\n安装 DockerDesktop 之后，你需要根据你已有的后端服务代码进行容器编排\n这一步主要是：\n建立 API 接口：编写主操作逻辑，这里的主操作逻辑可以使用任何你喜欢的编程语言来编写 创建必要的环境文件：例如 .env pyproject.toml 等环境文件 创建 DockerFile：其实就是一个命令行指令集，用来初始化你的容器 创建 docker-compose.yml 文件：在这个文件中你需要去编排你的 app 用到的镜像，指定内部网络、端口、挂载卷等等必要设置 然后一个命令：docker-compose up --build\nDocker 初始化完成之后，你就可以直接通过 localhost 这个域名来访问你的服务了，就和使用云服务器的效果一样。\nDocker路径问题 # 在编排 Docker 容器的时候，有几个必要的工作路径参数需要了解，否则很容易产生\u0026quot;文件无法找到\u0026quot;的错误😢\nbuild.congtext：这个参数存在于 docker-compose.yml 中，就是所谓的\u0026quot;构建上下文\u0026quot;，指向的是你本地的一个真实的目录 WORKDIR：这个参数存在于 Dockerfile 文件中，用来指定\u0026quot;工作路径\u0026quot;；后续的 RUN、COPY 等指令如果你使用了相对路径则都会在这个路径中执行，但是不影响绝对路径参数 端口转发 # 如果你在自己的本地构建了一个 Docker 服务，但是你的团队成员又需要有一个统一的测试环境，那么直接在你的本地服务的基础上进行端口转发就行了。\n能够支持端口转发的应用很多，这里不一一列举了，本人使用的是Sakura Frp\n虽然直接进行端口转发非常方便，但是如果你需要进行前后端的交互，那么最好不要使用端口转发😢\n我原本的思路是：前端网页跑在本地，然后后端服务也跑在本地的 Docker 里面，然后使用端口转发，把前端网页转发给用户，把后端转发给前端。\n看上去没什么问题，但是由于你的网络服务没有经过 SSL 验证，无法发送 https 请求，就导致浏览器阻止了前端向后端进行跨域的不安全资源请求😢最后的结果就是，只有你的电脑能够跑通完整的服务流程，别设备都会失败；即便配置了自签名证书，也很难通过客户端的浏览器的安全机制😭\n最后尝试未果，选择使用云服务器。\n云服务 # 现在云服务器的操作流程已经非常简单了，但是有一个缺点：贵😢\n当然，如果不是生成环境而是测试开发环境的话，也不用选择特别顶尖的服务器，根据自身财力和团队成员数量，选择一个合适的就行\n我最终选择的是腾讯云的轻型服务器： 2核+2G运存+4M带宽+50G系统盘+300G月流量\n没有别的理由，主要就是便宜，首年才 ￥88\n云服务操作流程 # 注册域名 # 设置 DNS 解析 # 购买云服务器 # 配置服务器 # 我这里使用的服务器操作系统是 Ubuntu Server 24.04 LTS 64bit，后续操作命令也是基于这个系统\n文件传输 # 为了从本地传输文件到服务器上，我选择使用一些更为现代化的终端，比如：Tabby, WindTerm 和 Warp 等等\n我随便选择了 Tabby 这个终端，它可以更加方便地进行远程连接，并且内嵌了 SFTP 方便传输文件，而且如果你有精力来折腾终端界面，那么 Tabby 还是能够非常美观的😄\n当然，传统一些的方案可以选择使用 FileZilla；而且不怕麻烦的话直接用终端命令也是可以的：使用 rsync 或者 scp 命令就行\n如果你用的是腾讯云的服务器，同时你也好奇 lighthouse 文件夹是什么🤨：这个文件夹就是一键免密登录的账户 安装Docker # 逐条执行下面的命令即可，每条命令都有说明：\nsudo apt-get update # 升级 sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release # 安装依赖工具，主要是https传输和验证相关的工具包 # 安装Docker的GPG密钥，为了确保你下载的Docker镜像没有被篡改 sudo curl -fsSL https://mirrors.cloud.tencent.com/docker-ce/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc # 将Docker的官方软件仓库添加到系统的APT源列表中 # 我觉得你不会想知道这一堆到底是什么意思٩(•̤̀ᵕ•̤́๑) sudo install -m 0755 -d /etc/apt/keyrings sudo chmod a+r /etc/apt/keyrings/docker.asc echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://mirrors.cloud.tencent.com/docker-ce/linux/ubuntu/ \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # 更新一下，让apt能够识别新添加的Docker软件源 sudo apt-get update # 安装Docker引擎 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # 启动Docker sudo docker info # 验证安装信息 sudo systemctl start docker # 启动服务 sudo systemctl enable docker # 开机自启 sudo systemctl status docker # 验证服务状态 运行完最后一条指令，会进入分页查看日志模式，类似于一个 Vim 编辑器，输入 :q 回到常规命令行 使用Docker # sudo systemctl start docker # 启动服务 # 配置腾讯云的Docker源 sudo vim /etc/docker/daemon.json # 创建配置文件 # 点击键盘I键，切换到I模式，并输入 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34; ] } # 按下esc，再输入 \u0026#39;:wq\u0026#39;，这是Vim操作，意思是保存并退出 sudo systemctl restart docker # 重启Docker服务 sudo systemctl stop docker # 停止Docker服务 # 验证源信息，你应该能看到Registry Mirorrs的值是你设置的网址 sudo docker info # 拉取镜像 sudo docker pull nginx # 如果你想使用docker-compose # 在Ubuntu上请使用：docker compose sudo docker compose up --build # 启动服务但不重新构建 sudo docker compose up -d # 停止所有服务 sudo docker compose down 在使用 docker compose 命令之前，请按照官方教程自行创建 docker-compose.yml 和 Dockerfile 配置pip/poetry # 很奇怪，腾讯云在系统层面默认安装了 Python，但是没有安装 pip 🤔所以需要手动安装一下，在安装前请先确认一下 Python 是否安装\n如果你使用的不是系统层面的 pip，而是 Docker 容器内部的 pip，那么对外部系统层面的 pip 进行换源操作没有效果 系统层面更换 pip 源：\n# 查询Python版本 python3 -V # 查看python3的路径 which python3 # 确认安装了python并且没有安装pip sudo apt install python3-pip # 如果使用的是腾讯的服务器，可以使用内网域名，速度更快 pip config set global.index-url https://mirrors.tencentyun.com/pypi/simple # 如果不是，那就使用外网域名 pip config set global.index-url https://mirrors.cloud.tencent.com/pypi/simple Docker 容器内部更换 pip 源：直接在你的 Dockerfile 文件里面写入如下命令\n# 配置pip源 # 使用腾讯云镜像源，注意这里是内网域名 RUN pip config set global.index-url https://mirrors.tencentyun.com/pypi/simple \\ \u0026amp;\u0026amp; pip config set global.trusted-host mirrors.tencentyun.com 如果你在系统层面使用 poetry：\n# 使用在线脚本安装poetry curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python # 使用apt安装poetry sudo apt install python3-poetry # 使用腾讯云镜像源，注意这里是内网域名 sudo poetry config repositories.tencentyun https://mirrors.tencentyun.com/pypi/simple 如果你的系统没有默认安装 pip，那么不建议先安装 pip 再安装 SSL/TLS # SSL/TLS 是一套加密传输协议，经过密码学专家的精心设计。我们现在广泛使用的超文本安全传输协议(HTTPS)就是在明文传输协议 HTTP 的基础上使用 SSL/TLS 加密后得到的。\nHTTPS核心的一个部分是数据传输之前的握手，握手过程中确定了数据加密的密码。在握手过程中，网站会向浏览器发送SSL证书，SSL证书和我们日常用的身份证类似，是一个支持HTTPS网站的身份证明，SSL证书里面包含了网站的域名，证书有效期，证书的颁发机构以及用于加密传输密码的公钥等信息。浏览器在生成密码之前需要先核对当前访问的域名与证书上绑定的域名是否一致，同时还要对证书的颁发机构(CA)进行验证，如果验证失败浏览器会给出证书错误的提示。\n一般 SSL 证书需要向 CA 机构购买，但是也有一些 CA 机构提供了免费的 SSL 证书服务，比如：Let’s Encrypt\n并且经过长期发展，Let’s Encrypt 颁发的证书已经可以通过 Certbot 来进行自动化处理了，证书到期了还能自动再次申请。当然如此的方便自然是要付出一些代价的😢：你需要配置 certbot，不得不说还是挺麻烦的\n这里我选择直接在 Docker 容器内部部署一个 certbot 来进行 SSL 证书的申请，也就是说可以直接修改 docker-compose.yml 中的内容，拉取官方的 certbot 镜像。\n# 先关停所有的Docker服务 sudo docker compose down # 启动所有服务 sudo docker compose up -d # 启动某部分服务 sudo docker compose up nginx -d # 查看特定镜像的日志 sudo docker logs server-app-1 # 查看特定服务的日志 sudo docker compose logs certbot-init # 使用递归删除来清除缓存 rm -rf ./certbot/conf/* # 进入一个镜像内部 sudo docker exec -it server-app-1 /bin/sh # 删除某个镜像 sudo docker rmi -f server-frontend # 重新启动某项服务 sudo docker compose restart app # 清理npm的缓存 npm cache clean --force # 激活python虚拟环境 source your_venv_name/bin/activate 备案 # 使用企业主体进行备案没有什么难度，因此不过多赘述，这里主要讲一下个人主体备案。主要参考：腾讯云服务器备案全流程 40天备案的血与泪-博客园\ngraph LR; p1(服务器平台实名认证)--\u003ep2(实名认证购买域名)--\u003ep3(申请备案)--\u003ep4(平台审核)--\u003ep5(管局审核)--\u003ep6(公安备案) 如果你是腾讯云用户，那么就可以使用腾讯云网站备案小程序；提交申请之后平台会先进行审核，一般 8 个小时左右；然后平台会提交管局审核，一般 7 个工作日左右；在管局审核通过之后需要在 30 个工作日内进行公安备案，\n杂项 # 这里主要写一下整个操作过程中可能遇到的问题。\ncertbot访问被拒绝了？ # 首先，当然是检查网络原因，检查一下服务器的安全组放行的端口有没有 443 和 80 端口，检查一下服务器操作系统的防火墙有没有拦截端口访问。\n# Ubuntu默认安装uwf防火墙 # 查看uwf状态，inactive状态是未启动，也是理想状态 sudo ufw status 如果你是国内用户的话，还有一个原因：ICP 备案没有通过，certbot 也是无法访问你的服务器的😢\n引用 # 使用第三方 SSH 终端登录 Linux 实例-操作指南-腾讯云 使用本地自带 SSH 终端登录 Linux 实例-操作指南-腾讯云 在 Linux 环境中安装 Docker Ubuntu 22.04安装Docker Docker 的官方 GPG 密钥到底是干什么的？ 云服务器 搭建 Docker-实践教程-腾讯云 安装 Docker 并配置镜像加速源-实践教程-腾讯云 Debian 12 / Ubuntu 24.04 安装 Docker 以及 Docker Compose 教程-烧饼博客 手把手教你在Linux系统下进行Python pip换源操作-腾讯云 pip源配置-腾讯云开发者社区-腾讯云 poetry如何更换国内源-数据科学SourceResearch Linux停止 Docker 容器：单个、多个或全部 docker日志在哪看?怎么在Linux服务器中查看日志-CSDN博客 Linux 防火墙关闭后仍无法访问 Web 的问题排查与解决 关于ubuntu控制台开放了所有端口,但是外部主机依然无法访问对应端口服务问题_ubuntu端口开放后不通-CSDN博客 三分钟带你详解SSL认证与加密技术-CSDN博客 一篇文章让你彻底弄懂SSL/TLS协议 - 知乎 HTTPS 与 SSL 证书概要 | 菜鸟教程 常用的四种免费证书申请方式-CSDN博客 使用docker部署nginx并配置https - TandK - 博客园 使用 Docker + Nginx + Certbot 实现自动化管理 SSL 证书-CSDN博客 The Certificate Authority failed to download the temporary challenge files created by Certbot \u0026ndash; Connection refused - Help - Let\u0026rsquo;s Encrypt Community Support ICP 备案 首次备案_腾讯云 ICP 备案 各省管局要求_腾讯云 腾讯云服务器备案全流程 40天备案的血与泪 - 郑为中 - 博客园 ICP 备案 公安备案流程_腾讯云 ICP 备案 视频核验_腾讯云 npm缓存深度解析：理解、使用与清除指南_npm 清除缓存-CSDN博客 用Docker部署一个Web应用 - 知乎 HTTPS请求为什么会降级为HTTP-CSDN博客 https 被redirect成了http_风控-CSDN博客 如何填写公安联网备案公安联网备案信息指南_备案(Filing Service)-阿里云帮助中心 ","date":"2025-03-06","externalUrl":null,"permalink":"/blog/cloud-server-build/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  详细记录了从零开始发布 LLM 应用的过程，主要内容关注云服务器的初始化搭建过程，持续更新中\u0026hellip;\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在发布你的 LLM 应用之前，你应该已经基本完成了：\u003c/p\u003e","title":"云服务搭建","type":"blog"},{"content":" 详细记录了Qdrant向量数据库的核心功能，让开发者在实际应用过程中设计出更好的数据库😋 前言 # 基于向量数据库的 RAG 是最基础的 RAG 形式，在实际生产中被广泛应用。正如其名，向量数据库主要存储的元素是一个个的向量，通过向量运算，我们能够实现更加精准地相关性搜索，这个功能是一些应用场景地基石。\n向量数据库的供应商有很多：Weaviate、Qdrant、Milvus、Chroma……等等。但大体上都差不多，详细的主流向量数据库对比分析报告见：向量数据库比较报告:12款主流向量数据库详细对比\n这里就只关注 Qdrant 这一个供应商。所有内容均参考 Qdrant官方文档 (2025-03)\n并且这篇文章较少涉及具体的代码语法，重点关注功能和原理，帮助开发者更加快速地设计产品工作流程，而不是被繁琐的语法限制了想象力和工作效率。\n基础数据类型 # Qdrant 为了更好地处理向量数据定义了一些抽象数据类型，理解这些类型是灵活运用的基础。\n数据点·Point # 数据点是向量数据库的核心数据类型，所有的操作都围绕着数据点进行。\n一个非常纯净的数据点只包含其向量，但是一般情况下数据点都会被附加上一些标签用来提供向量数据之外的更多的信息。这些标签被称为负载·Payload 👇\n因此：数据点=向量+负载标签\n// 这是一个简单的数据点 { \u0026#34;id\u0026#34;: 129, \u0026#34;vector\u0026#34;: [0.1, 0.2, 0.3, 0.4], \u0026#34;payload\u0026#34;: {\u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;}, } Qdrant 的数据点能够配置多种不同类型的向量：密集向量，稀疏向量、多重向量和命名向量\n向量类型 描述 密集向量 就是一般意义上的向量；大部分嵌入模型生成的向量都是这个类型 稀疏向量 长度非固定，只有少量非零元素；一般用于精确的词元匹配和协同过滤 多重向量 多个密集向量构成的矩阵，不同数据点之间密集向量的维度必须相同，但向量的个数不比相等；用于存储同一个目标的不同向量描述 命名向量 上述三种类型的向量的混合，允许不同类型的向量存储在同一个数据点内，这些不同类型的向量构成的集合被抽象为所谓的命名向量 然后就是数据库基本的增删改查操作，不必赘述。\n负载·Payload # 被附加在向量上的额外元数据信息，使用 JSON 语法描述并存储，下面是一个例子\n{ \u0026#34;name\u0026#34;: \u0026#34;jacket\u0026#34;, \u0026#34;colors\u0026#34;: [\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;], \u0026#34;count\u0026#34;: 10, \u0026#34;price\u0026#34;: 11.99, \u0026#34;locations\u0026#34;: [ { \u0026#34;lon\u0026#34;: 52.5200, \u0026#34;lat\u0026#34;: 13.4050 } ], \u0026#34;reviews\u0026#34;: [ { \u0026#34;user\u0026#34;: \u0026#34;alice\u0026#34;, \u0026#34;score\u0026#34;: 4 }, { \u0026#34;user\u0026#34;: \u0026#34;bob\u0026#34;, \u0026#34;score\u0026#34;: 5 } ] } 既然都存进数据库里面了，那么这些数据肯定是有作用的：向量数据库的搜索机制主要是语义近似匹配，通过这些标签你就能够在这个基础上添加更多的逻辑过滤条件\n关于过滤的更多信息见：过滤·Filtering\n集合·Collection # Collection 简而言之就是一组数据点的集合。在这个数据类型的层面上你能够定义：\n数据点之间的相似度算法 向量的维度 优化器配置 HNSW 算法配置：需要调整的参数是 ef，用来确定算法访问邻接结点的个数，数值越大查询越准确，速度越慢 WAL 配置 量化配置 常见操作 # 这是向量数据库使用过程中的最基础也是最重要的一些操作。\n搜索·Search # 搜索在向量数据库的语境下主要指的是相似度搜索，其重要理论前提就是：在现实世界中相似度更高的对象在向量空间中更接近\n而其中\u0026quot;更接近\u0026quot;一词则暗含了一种衡量相似度的算法，Qdrant 中支持了一些最流行的相似度算法：\n点积相似度 余弦相似度 欧氏距离 曼哈顿距离 为了提高数据库的性能，所有向量在存入的时候都会被\u0026quot;归一化\u0026quot;，这也意味着点积相似度和余弦相似度在 Qdrant 中是等价的 为了更良好的用户体验，Qdrant 提供了一套完整的程序接口，让用户能够方便地调用：Search API - Qdrant\n概括下来，你能够调用功能大概有这些：\n基本操作：输入一个向量，在数据库中进行相似度匹配；如果你的数据点存储了\u0026quot;命名向量\u0026quot;，那么你需要指定用哪个特定的向量去进行相似度匹配 调控搜索算法：可以控制是否使用精确搜索，如果启用，那么相似度匹配会在每一个数据点上执行，耗时更长(还有更多的参数可调，但是一般不用) 结果过滤：在实际执行搜索之前，按照负载标签进行过滤，减小搜索范围；实际执行搜索之后，使用相似度评分阈值来过滤 结果数量：参数 limit 控制搜索出来的结果的数量，也就是相似度评分最高的 limit 个 批量搜索：一次性输入一组向量进行搜索 搜索分组：能够对搜索结果按照某些标签进行分组，参数 group_size 可以设置每组的结果个数 搜索规划：依据可选索引、过滤条件的复杂性和总共的数据点的数量，以启发式的方法选择一个合适的搜索方式(提高性能🤔) 如果 group_size 和 limit 被同时设置，那么此时 limit 参数表示分组的数量 另外，在 Qdrant 中，稀疏向量和密集向量的搜索有一些关键的不同，对比结果如下：\n对比项 稀疏向量 密集向量 相似度算法 默认使用点积相似度，不用指明 你可以指定受支持的算法 搜索方式 只能精确搜索 可以使用 HNSW 算法进行模糊搜索 搜索结果 只返回含有共同非零项的向量 返回你设置的 limit 个向量 探索·Explore # 探索操作直观来说就是更加灵活的搜索操作：能够依靠相似度进行搜索的同时，也能够依靠区分度来查询\n推荐·Recommendation # \u0026ldquo;推荐\u0026quot;允许你同时提供一个正面的向量和反面的向量来进行搜索，下面是官方给出的例子：\nimport { QdrantClient } from \u0026#34;@qdrant/js-client-rest\u0026#34;; const client = new QdrantClient({ host: \u0026#34;localhost\u0026#34;, port: 6333 }); client.query(\u0026#34;{collection_name}\u0026#34;, { query: { recommend: { positive: [100, 231], negative: [718, [0.2, 0.3, 0.4, 0.5]], strategy: \u0026#34;average_vector\u0026#34; } }, filter: { must: [ { key: \u0026#34;city\u0026#34;, match: { value: \u0026#34;London\u0026#34;, }, }, ], }, limit: 3 }); 官方给出的例子中 100,231 是向量编号，每一个编号都对应一个四维的向量 其中 strategy 参数用于调控搜索算法，下面是具体的算法说明：\n平均算法：对正例、反例分别进行平均，得到的两个向量再进行加权平均，产生最终用于搜索的向量\n最佳评分算法：每一个待搜索的数据点都会分别和正例负例中的所有数据点进行匹配得出评分，然后分别选出最高评分，然后按照如下计算方法得出这个待搜索的数据点的最终评分\nlet score = if best_positive_score \u0026gt; best_negative_score { best_positive_score } else { -(best_negative_score * best_negative_score) }; 只考虑负例算法：使用最佳评分算法👆同时不提供正例，你就会得到一个反向评分算法，能够找到最不相关的数据点 多重向量和别的特殊向量也是能够被处理的，处理逻辑相同，只是代码写法不同 发现·Discovery # \u0026ldquo;发现\u0026quot;操作的核心思路就是样本空间的分割。你需要提供一系列的正负向量对，每一个向量对都会将样本空间划分为正区域和负区域，最终将会搜索得出处于正区域更多或者负区域更少的数据点。\n和推荐·Recommendation 类似，但是这里你需要将正向量和负向量组合成一对来输入。\n由于进行了样本空间的硬划分，因此可以考虑提高 HNSW 算法中的 ef 参数来弥补硬划分产生的精度损失 通过发现操作，Qdrant 能够处理一下两种新的搜索需求：\n发现型搜索：给定一个搜索目标向量，同时提供一系列正负向量对作为上下文约束条件；\n区域划分搜索：是发现型搜索👆的特例，在不提供目标向量的情况下，数据库会直接使用正负向量对进行区域划分，并最后返回处在正区域中最多的数据点\n在发现型搜索中，通过算法保证了上下文约束条件的强制性，优先级更高；换言之，发现型搜索先执行区域划分搜索，然后再进行普通的相似度搜索 距离矩阵·Distance-Matrix # 这个操作很类似于批量搜索。批量搜索的流程是：用户输入一批向量数据点，然后在数据集合中逐个搜索这些向量数据点的相似向量。而距离矩阵的流程是：系统随机选取一些向量数据点构成一个样本子集，然后对每一个向量数据点都在这个样本子集里面去搜索相似向量。\n例如，系统随机选取 sample=100 个数据点，构成一个含有 100 个数据点的样本子集，然后设置每个数据点搜索出最相似的 limit=10 个数据点，那么最后返回的距离矩阵将会是一个 \\(100\\times 10\\) 的矩阵，每一行代表着其中一个数据点的最相似的 10 个数据点。\n这个操作一般用于数据可视化或者数据降维。\n过滤·Filtering # 官方英文指南：A Complete Guide to Filtering in Vector Search；这份指南中的前面部分直观地解释了 Qdrant 内部是如何执行过滤操作的，了解之后更有助于设计一个高效的体系。\n指南中只是简要列举了一些功能，更完整详细的功能文档见：Filtering\n过滤条件 # 这里的过滤条件专指单个过滤条件，是过滤操作的基本单元。下面是具体的类型列表：\n类型 功能 Match 过滤条件是一个具体值，属性值必须和过滤条件完全相等 Match Any 过滤条件是一组选项，属性值在过滤条件中存在即可 Match Except 过滤条件是一组选项，属性值不在过滤条件中存在即可 Range 过滤条件是一个范围，属性值需要在范围之中 Values count 属性值是一个数组，依据数组中元素数量来过滤 Is Empty 以属性值是否存在为依据来过滤 以上就是最基本的过滤类型，针对不同的负载类型，其语法上会有一定差异：\nJSON负载：一个数据点的负载可以是一个 JSON 对象，这个 JSON 对象中的任意字段都可以参与过滤；具体语法见官方网站：Nested key 日期范围：类似于普通的数值范围，日期范围也支持过滤 地理过滤：地理位置也支持过滤 命名向量：命名向量中含有多个不同维度的向量，可以根据特定的向量是否存在来过滤，例如可以过滤出\u0026quot;含有图片嵌入向量\u0026quot;的命名向量 这些基本的过滤条件可以通过下面的方法进行嵌套，形成复杂的过滤条件👇\n逻辑关键字 # 类似于 SQL 中的关键字 AND OR NOT，在 Qdrant 中使用 must should must_not 来表达类似的逻辑。通过逻辑关键字，能够构建一个复杂的过滤器。\nmust：当所有列出的过滤条件都被满足的时候才会返回真 should：当所有列出的过滤条件中有一个被满足就会返回真 must_not：当所有列出的条件都不被满足的时候返回真 高级操作 # 混合查询·Hybrid Queries # 优化·Optimizer # 存储·Storage # 索引·Indexing # 快照·Snapshots # 引用 # 向量数据库比较报告:12款主流向量数据库详细对比 | 数荣量标-SynDataWorks Qdrant官方文档 ","date":"2025-03-05","externalUrl":null,"permalink":"/blog/qdrant-feature-guide/","section":"Blogs","summary":"\u003cp\u003e\n\n\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  详细记录了Qdrant向量数据库的核心功能，让开发者在实际应用过程中设计出更好的数据库😋\n\u003c/div\u003e\n\u003c/p\u003e","title":"Qdrant功能指南","type":"blog"},{"content":" 这是一个以构建一个LLM应用为目标驱动的独立全栈开发流程，囊括了各种开发过程中遇到的问题； 同时这篇博客也是“AI工程”系列的〇号文章，作为整个系列的索引之外，也总结一下心得体会； 前言 # 当我们已经习惯了随手点开一个 AI 聊天助手：豆包、Kimi、DeepSeek……功能如此简单的一个东西，貌似自己写一个也不会很困难吧？\n这就是属于我的那个\u0026quot;梦开始的地方\u0026quot;😢听着很扯，但我当时真是这么想的。然后就有了后面漫长的开发之旅。\n如果你也有和我类似的想法，那么下面的内容可能对你有所帮助🤗\n在熬过了这么多夜之后，我必须承认\u0026quot;构建一个 LLM 应用\u0026quot;是一个非常庞大的话题，特别是对于一个独立开发者而言。如果你选择了做独立开发或者组建一个微型团队，那么也同时意味着你选择了一个艰辛的道路：没有\u0026quot;前辈\u0026quot;帮你探索技术路线，一切的一切都要靠你自己去摸索。\n但是，这也是独立开发的乐趣所在：你能够完全掌控你的产品的走向，看着它一点一点迭代优化。\n你可能会问：\u0026ldquo;产品做出来效果不好怎么办？\u0026quot;；\u0026ldquo;开发不下去了怎么办？\u0026quot;；\u0026ldquo;如果没什么人用那我的时间不是打水漂了？\u0026quot;🤔\n不得不说，独立开发的投入真的很高昂，而且上述疑问都是无法避免的，甚至对于大部分独立开发者来说是必然会经历的。\n但是，如果你真的认真对待了\u0026quot;独立开发\u0026quot;这件事情，不管结果如何，我相信你都有所收获：如果你成功了，我在这里对你表达祝贺🥳你的辛勤付出有了回报；如果你失败了、放弃了，我理解你的不甘与沮丧，甚至是愤怒。\n但是没人能够在对自己过往的全盘否定中收获快乐与成功，暂时忘掉那些伤痛，继续下一步的人生吧。\n人生没有白走的路，每一步都算数🫡\n发现需求 # 草稿草稿草稿……\n探索实现方案 # 草稿草稿草稿……\n项目构建 # 草稿草稿草稿……\n发布服务 # 云服务搭建 ","date":"2025-03-04","externalUrl":null,"permalink":"/blog/llm-app-driven-fullstack-dev/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  这是一个以构建一个LLM应用为目标驱动的独立全栈开发流程，囊括了各种开发过程中遇到的问题；\n同时这篇博客也是“AI工程”系列的〇号文章，作为整个系列的索引之外，也总结一下心得体会；\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e当我们已经习惯了随手点开一个 AI 聊天助手：豆包、Kimi、DeepSeek……功能如此简单的一个东西，貌似自己写一个也不会很困难吧？\u003c/p\u003e","title":"LLM应用驱动的独立全栈开发指南","type":"blog"},{"content":" Neo4j图数据库的基础信息以及操作方法 简介 # Neo4j 是一个高性能的图数据库，将数据以及数据之间的关系通过图的形式来存储。图的具体形式是标签属性图，使用的查询语言是 Cypher。\n标签属性图 # 标签属性图是一种特定类型的图：\n一个结点有一个或者多个标签来进行类型的定义 关系和节点地位相同，被视为同等重要 每个节点和关系都拥有可供访问的属性 Cypher # Cypher 是一种声明式查询语言，允许你使用类似ASCII艺术风格的语法（包括括号、破折号和箭头）来识别数据中的模式。\n模式 # 模式是图数据库中的特定的结点和关系的组合，例如一个人（Person）在一个电影（Movie）中出演（ACT_IN）就是一个模式，代码形式表示为：\n(p:Person)-[r:ACT_IN]-\u0026gt;(m:Movie) 其中用小括号选中的部分是结点，用方括号选中的部分是关系。结点部分中 p，m 是指代相应结点的变量，Person 和 Movie 是对应结点的标签，中间用冒号连接。关系部分中 r 是指代关系的变量，ACT_IN 是特定的关系类型。直接翻译成自然语言，意思就是：用 p 指代包含 Person 标签的结点，用 m 指代包含 Movie 标签的结点，他们之间的关系用 r 表示，类型是 ACT_IN\n数据读取 # 数据读取操作依赖模式匹配，使用关键字 MATCH，这相当于给数据库发送指令，让它过滤出只符合特定关系的结点关系对，也就是三元组 (p,r,m) 构成的集合\nMATCH (p:Person)-[r:ACT_IN]-\u0026gt;(m:Movie) 类似于 SQL，你还可以使用关键字 WHERE 进行进一步的筛选：\nMATCH (p:Person)-[r:ACT_IN]-\u0026gt;(m:Movie) WHERE p.name = \u0026#39;Tom Hanks\u0026#39; RETURN p,r,m name 就是结点 p 的一个属性，使用 . 操作服来访问节点的额属性；RETURN 关键字标记返回值。\n下面是一个更加复杂的模式匹配命令代码，AS 关键字用来设置别名：\nMATCH (p:Person)-[:ACTED_IN]-\u0026gt;(m:Movie)\u0026lt;-[r:ACTED_IN]-(p2:Person) WHERE p.name = \u0026#39;Tom Hanks\u0026#39; RETURN p2.name AS actor, m.title AS movie, r.role AS role 这个命令筛选出和 Tom Hanks 参演过同一场电影的所有演员，并给出他们的名字、参与的电影、在电影中饰演的角色\n按照某个属性来进行排序以及分页也是支持的：\nMATCH (m:Movie) WHERE m.released IS NOT NULL RETURN m.title AS title, m.url AS url, m.released AS released ORDER BY released DESC LIMIT 5 这会筛选出最新的 5 个电影。\nCypher 关键字对大小写不敏感；属性名、变量名等其他的都是大小写敏感的 数据写入 # 数据写入使用 MERGE 关键字，其含义就是将一个结点或者关系合并进数据图中。\n合并结点： MERGE (m:Movie {title: \u0026#34;Arthur the King\u0026#34;}) SET m.year = 2024 RETURN m 这个命令代码会创建一个新的 Movie 结点，其 title 属性被设置为 \u0026quot;Arthur the King\u0026quot;，year 属性被设置为 2024；\n你可能会疑惑为什么不这样写：\nMERGE (m:Movie) SET m.year = 2024, m.titile = \u0026#34;Arthur the King\u0026#34; RETURN m 其实大括号内的内容被用于检查你想创建的模式是否已经存在，避免重复创建模式。\n合并关系： MERGE (m:Movie {title: \u0026#34;Arthur the King\u0026#34;}) MERGE (u:User {name: \u0026#34;Adam\u0026#34;}) MERGE (u)-[r:RATED {rating: 5}]-\u0026gt;(m) RETURN u, r, m 安装 # 目前时间 2025-02-15，经过广大开发者的测试，发现 Neo4j Desktop 对于国内的用户有封锁，导致软件界面无法正常显示。虽然可以通过关闭网络等手段破除封锁，但是这样就失去了桌面版独特的优势：方便部署；\n因此这里主要推荐并介绍使用 Docker 部署的流程；\n操作系统：Windows 11\nDocker Desktop # 无话可说，安装后启动放后台即可\n拉取镜像 # 一般来说直接无脑拉取最新镜像就行：docker pull neo4j\n但是如果你的项目硬性需要 APOC 的话，就需要考虑最新的 APOC 版本，因为镜像有可能领先 APOC 的版本；社区版发布在 Releases · neo4j/apoc\n目前考虑 APOC 兼容的话请使用：docker pull neo4j:5.26.2\n构建容器 # docker run -d -p 7474:7474 -p 7687:7687 -v E:/neo4j/data:/data -v E:/neo4j/logs:/logs -v E:/neo4j/conf:/var/lib/neo4j/conf -v E:/neo4j/import:/var/lib/neo4j/import -v E:/neo4j/plugins:/var/lib/neo4j/plugins -e NEO4J_dbms_security_procedures_unrestricted=\u0026#34;apoc.*\u0026#34; -e NEO4J_dbms_security_procedures_allowlist=\u0026#34;apoc.*\u0026#34; -e NEO4JLABS_PLUGINS=\u0026#39;[\u0026#34;apoc\u0026#34;]\u0026#39; -e NEO4J_AUTH=neo4j/mo123456789 --name neo4j neo4j:5.26.2 参数说明：\n-p 参数用于暴露端口，这里开放了两个端口 -v 参数用于宿主机的目录挂载（说人话就是指定这个 Docker 应用的存储目录） -e 参数用来配置环境变量：带有 apoc 的都是 APOC 相关的配置；NEO4J_AUTH 表示用户名为 neo4j，密码为 mo123456789； 如果你使用 Neo4j 用于语言模型的增强生成(RAG)，一定要带上述 APOC 相关配置；如果不是的话，那么那些命令可以直接去掉 运行完上面的命令之后可以去宿主机挂载目录中查看 APOC 插件是否安装：\n手动安装 APOC # 去 Releases · neo4j/apoc 中最新的 Assets 中下载 apoc-5.26.2-core；然后粘贴到上面👆所说的宿主机目录中；然后重启 Docker 容器就行\n浏览器UI # 这里默认将 7474 端口给浏览器UI使用，7687 端口给别的后台程序使用；\n在容器运行在后台的情况下，访问：http://localhost:7474/browser/preview\n选择接入链接：neo4j://localhost:7687\n然后就可以成功进入浏览器UI界面了😄\n参考资料 # Docker：Docker部署Neo4j图数据库 - 怒吼的萝卜 - 博客园 ","date":"2025-02-05","externalUrl":null,"permalink":"/blog/neo4j-basics/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  Neo4j图数据库的基础信息以及操作方法\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e简介 \n    \u003cdiv id=\"%E7%AE%80%E4%BB%8B\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%AE%80%E4%BB%8B\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/neo4j/neo4j\" target=\"_blank\"\u003eNeo4j\u003c/a\u003e 是一个高性能的图数据库，将数据以及数据之间的关系通过图的形式来存储。图的具体形式是\u003cstrong\u003e标签属性图\u003c/strong\u003e，使用的查询语言是 \u003ccode\u003eCypher\u003c/code\u003e。\u003c/p\u003e","title":"Neo4j基础","type":"blog"},{"content":"TODO_UPDATE 日程管理软件功能现状分析报告 前言 # \u0026ldquo;日程管理\u0026quot;这个词在我们的生活中经常出现，但是又非常令人捉摸不透：日程管理到底是个啥？我们为什么需要它？它有什么作用？有哪些人在进行日程管理？效果如何？\n何为日程管理？ # 表面上‘日程管理’是一个常见概念，但实际上它涵盖了复杂且多元的内容。\n总的来说，日程管理是一种明确记录、规划、组织和优化个人或团队的时间与任务，以实现设定目标的管理方法。\n针对不同的需求，可以具体细分为以下品类：\n个人成长与自我提升：\n特点：完全取决于个人意愿，往往只有一个宏大的目标，没有明确的事件、时间，可能存在一个定量指标 主要目的：促进个人长期成长、提高生活质量和满足感 个人职业与学业管理：\n特点：有非常明确的事件、时间，不以个人主观意愿为主，往往还需要与他人协作，一般存在定量指标甚至不止一个 主要目的：实现具体的职业目标、提高职业技能和效率 社交与人际关系管理：\n特点：需要处理复杂的人际关系，没有定量指标，具有偶然性，可控性较低 主要目的：维护、拓展和优化人际关系网络，提高个人社会资本 财务与生活事务管理：\n特点：任务琐碎，频繁重复，灵活但又具有一定的周期性规律，持续时间一般不长 主要目的：保障生活的秩序感和稳定感 实际生活中，日程其实是上述几个方面的混合，因此当我们泛泛地提及\u0026quot;日程管理\u0026rdquo;，其实我们就模糊地指代了\u0026quot;管理生活的方方面面\u0026quot;，导致人们对于日程管理的认知非常模糊。\n何谓\u0026quot;好的\u0026quot;日程管理 # 一般来说，“好的日程管理”是一套清晰明确、现实可行、富有弹性，且能有效平衡长期目标与短期行动，具备定期反馈与持续调整机制，显著提高个人掌控感并降低压力，且易于持续记录与执行的管理体系。具体来说需要满足以下标准：\n清晰明确的目标导向性（Goal Clarity） 可执行性和合理性（Realistic and Executable） 灵活且有韧性（Flexibility \u0026amp; Resilience） 长期与短期平衡（Balance between Long-term and Short-term） 反馈与调整机制（Feedback and Adjustment） 降低心理压力，提高掌控感（Reduce Stress and Enhance Control） 易于使用且有明确的记录方式（Ease of Use \u0026amp; Clear Recording） 但是从用户体验的角度来说，“好的日程管理”其实只用回答下面这几个问题：\n如何收集必要信息：用户日程、用户偏好、天气信息、网络资讯等等 如何处理上述信息：根据不同的日程类型进行不同的处理流程 如何降提升用户体验：精简而有温度的交互方式、直观简洁的信息呈现 行业现状 # 现有的日程管理解决方案罗列如下，但是说实话，日程管理这个赛道的应用国内真的不多，国外的应用虽多但存在严重的同质化\n滴答清单 # 滴答清单的功能覆盖全面，设计风格简洁，是一个经典的静态日程管理应用。它的日程管理逻辑大概如下：\ngraph LR; id1(\"日程收集\")--\u003eid2(\"手动日程安排\")--\u003eid3(\"按时执行日程\"); id2(\"手动日程安排\")--\u003eid4(\"没有按时执行日程\")--\u003eid5(\"手动进行调整\"); Dola # Dola 非常具有未来气息的一款 AI 日程管理软件：完全没有软件界面，与 AI 的交流全部通过常见的消息平台，例如 WhatsApp，Apple Messages 等。但是完全不支持国内的主流软件例如 QQ，微信等。\n根据官方说明大概绘制了一下体验流程图：\ngraph LR; id1(\"通过消息平台发送消息\")--\u003eid2(\"AI分析生成日程\")--\u003eid3(\"软件内部存储日程\"); id1(\"通过消息平台发送消息\")--\u003eid4(\"AI分析后修改日程\"); id1(\"通过消息平台发送消息\")--\u003eid5(\"AI分析后返回查询结果\") Motion # Motion 是一款主打 AI 驱动的工作管理软件，软件主要的服务群体是创业团队，在团队协作方面进行了很多的设计。在测试过程中重点测试了一下对于具体日程的安排效果，但是发现并没有那么好的效果。\n日程安排的主体逻辑就是：通过工作时间和私人时间来进行分块，然后 AI 就根据空闲时间来直接安排日程。最后的效果其实退化为了简单的日程插入：有空就会插入日程，即便这个工作的截止日期还有一个月，即便你这一天已经非常忙碌。\n总结 # 静态日程管理 # 手动安排调整日程是静态日程管理软件使用过程中必不可少的环节，也是是整个流程中最耗费精力的，静态日程管理应用虽然能够创建时间块来安排日程，但是对于缺乏动态调整的能力。这对于一些固定的、来自外界的日程并没有什么影响，因为它们一般都具有明确的起止时间。\n但是对于一些来自内在的、软性的、琐碎的日程，例如背 15 个单词、洗衣服、阅读杂志等。这些日程一般用于自我提升，没有明确的开始时间，只需要当天完成就行；同时也没有明确的结束时间，例如 15 个单词往往 30 分钟才能背完，结果某天状态良好 20 分钟就背完了。\n这些琐碎的日程对于静态的日程安排是一个不小的挑战。尽管单个琐碎日程的提前或者延误对于整个日程安排并无大碍，但是他们的累积效果对于静态日程安排的破坏非常明显。\n除此之外，这些零散的日程如果没有对齐的话，还会产生时间真空，导致用户在某个时间点突然不知道该干什么。例如，用户提前背完了单词，空余了 10 分中的时间。这十分钟该如何妥善处理？如果没有明确的安排的话，用户可能会选择在这 10 分钟刷短视频，然后紧接着又是一段休息时间，又继续刷视频。这不出意外会导致下一个任务因为时间不足而再次延误，然后又产生一段时间真空，如此延续。\n想要终止这种恶性传导，有三种对策：\n用户手动进行调整：这将非常非常麻烦，宝贵的时间浪费在了安排一些琐碎的事情上；并且手动调整所花费的时间也可能会导致任务的延误\n直接不进行调整，忽略具体的时间控制：这样做日程管理将失去其本身的意义，精确安排时间使得时间价值最大化。这个时候的日程安排完全退化为了一个任务表，失去了对于时间的控制作用，倒不如一开始就使用没有时间控制能力的更加专业的清单工具\n用户严格按照日程执行：理论很完美，实际上效果非常糟糕。生活中不可避免出现意外情况，如果出现延误，那么下一项任务的时间受到挤压，可能无法按时完成，或者匆忙完成导致效果不佳；如果提前完成，那么难以临时添加一个合适的任务填补时间真空，导致时间浪费的同时也不利于执行力和专注力的培养\n时间真空的恶性传导是静态日程管理软件的致命伤，严重限制了日程管理软件的普及程度。因此人们往往心照不宣地认为日程管理是一些极其自律的人的专属行为，日程管理软件也只是为这类人设计的小众软件。\n我自己曾经使用过一些静态日程管理软件，但都难以坚持：要么是软件的学习曲线过于陡峭，要么是难以遵循固定的日程安排 因此，一个真正有意义的时间管理软件不应该要求用户的生活没有任何意外，或者用户必须遵守日程安排，而应该给用户提供出现意外后的解决方案。\n动态日程管理 # 现有的动态日程管理应用已经在一定程度上解决了静态日程管理软件难以快速动态调整的问题，但是在智能化、个性化方面还受传统的日程管理思路的束缚，需要用户手动输入大量的信息，但这是一个很矛盾的地方：用户都手动输入这么多信息了，为什么还要 AI 来安排？那么多科学算法又快又准为什么不用呢？\n因此还需要有更大胆的尝试来释放大语言模型的强大的通用处理能力。\n认识现状 # 了解人们对于日程管理的认知程度以及需求是确定应用形态的重要依据。\n我们在小范围内进行了问卷调查，结果显示：\n大部分受访者只是偶尔进行日程规划 专门的日程管理软件的普及程度甚至不及手机自带的备忘录 有超过一半的受访者表示大部分日程规划都没能按照预期完成 在众多功能中“操作简单”成为呼声最高的功能，其次就是“个性化” 虽然样本量不多，但是可以做出如下推断：\n人们对于日程管理的认知程度不高 操作简单、降低用户使用门槛应该成为日程管理应用的基础 个性化也应成为一个需要重点优化的一个功能 技术方案 # 基于上面的调查内容，我们正式明确提出应用的发展目标：\n打破人们对于头脑中进行的日程规划很高效的虚假想象，打破人们对于ddl的严重依赖，解决传统日程管理软件使用成本过高、动态调整能力不足的痛点，解决现有AI难以捕捉用户隐性偏好、难以进行长短期目标综合规划的难题。让日程管理真正的落到个体的日常生活中去，实实在在提高办事效率和生活质量，达到真正的：轻松规划，简单生活(Easy Schedule, Simple Life)\n为了保证方案的可实施性，我们不考虑：社交与人际关系管理、财务记录和团队协作功能，只专注服务个体用户，满足其在个人成长与自我提升、生活琐事管理方面的需求。\n交互界面设计 # 要想交互界面简洁直观，最好的方式其实就是从生活中取材：老板通过与秘书的简单交流就能够完成日程的安排。\n因此交互界面就直接选用最最简洁的聊天对话框的形式，就类似于在 QQ、微信中和你的私人秘书发消息。\n必要信息收集 # 既然用户与系统的交互方式只是通过一个聊天对话框，那么所有用户相关的信息也都应该从用户的消息中获得。必要的信息有大致下面这几类：\n日程信息：用户有哪些事情要做，比如下周一之前要交学术英语写作的作业 用户偏好：用户不自觉地生活习惯，比如用户不喜欢学术英语的作业，经常拖延完成 日程执行信息：原本安排好的日程用户是否完成 其他客观信息：需要搜集网络上的信息，例如天气信息等等 其中，用户的日程信息是通过用户主动向系统发送消息来获取，用户的偏好通过用户对于某些安排得“不合理”的日程的调整来获得，其他客观信息系统根据情况从互联网上获取。\n这些信息经过必要处理之后都会进行长期存储，也就是存储到“记忆系统”，这个“记忆系统”从技术本质上来说就是 RAG：依赖向量数据库来存储日程和偏好，依赖关系数据库来存储被安排好的日程信息，直接把这两个数据库的操作权限开放给 AI，实现“记忆更新”\n信息处理 # “记忆系统”中的信息通过语义搜索与时间区间搜索，填充到提示词当中作为大模型安排日程的依据。\n同时有一个提前准备好的科学知识库提供给大模型，让它能够依据一定的科学原理来进行日程的安排。\n这样就能够兼顾科学性与个性化，让安排出来的日程真正被用户接受并执行\n信息呈现 # 为了保持“简洁性”，避免给用户呈现太多的非必要信息，因此只做两个信息呈现：\n聊天对话框 TODO List 通过聊天对话框完成日程的存入与安排，通过 TODO List 来收集用户执行情况的信息\n系统实现 # 系统整体的架构图如上所示，流程详述如下：\n用户的信息输入会直接保存到内部历史消息数据库内，供全局访问 参数提取步骤会利用大模型来对用户的输入进行参数提取，同时处理一些系统不支持的用户消息 提取参数之后就会从日程表和向量日程库中查询相关记忆并封装为 xml 模板提供给大模型，由模型决定下一步的操作，并提取出操作所需的参数 模型决定下一步需要的操作之后，数据库接口函数就会依据参数处理这些操作，对日程表和向量日程库进行更新 更新之后，系统会返回一个更新日志，并封装为 xml 提示词模板，提供给大模型生成一个合适的响应文本，呈现给用户 日程存储实现 # 向量日程库 # 日程表 # 参数提取实现 # 记忆查询实现 # 操作决策实现 # 数据库接口实现 # 响应文本实现 # 测试分析 # ","date":"2025-01-27","externalUrl":null,"permalink":"/blog/schedule-management-report/","section":"Blogs","summary":"\u003cp\u003eTODO_UPDATE\n\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  日程管理软件功能现状分析报告\n\u003c/div\u003e\n\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u0026ldquo;日程管理\u0026quot;这个词在我们的生活中经常出现，但是又非常令人捉摸不透：日程管理到底是个啥？我们为什么需要它？它有什么作用？有哪些人在进行日程管理？效果如何？\u003c/p\u003e","title":"日程管理项目分析","type":"blog"},{"content":" 总结 CUMCM2024 比赛经验，针对数学建模国赛 A 题和MATLAB改进的代码协同方案 流程概览 # graph LR; id1(\"工作分配\")--\u003eid2(\"VS Code协同\")--\u003eid3(\"MATLAB代码执行\"); 工作分配 # 主要有两个要点：\n划分为两个部分，一个主要部分和次要部分； 划分的任务之间不要有依赖关系 代码协同 # 软件工具 # VS Code 编辑器，以及 Live Server 插件，MATLAB 插件\nMATLAB\n命名规范 # 主函数统一命名为 main：能够直接计算出最终答案的叫主函数，其他的都叫辅助函数 数据加工代码：数据加工代码指的是没有任何返回值，仅仅产生数据表格的代码，用 data 开头，例如：将太阳高度角 \\(\\phi\\) 转化为余弦值，dataCosPhi 内部数据转换代码，用 to 连接，例如将自然坐标系中点的坐标转化为直角坐标系中点的坐标 StoXY 绘图代码：绘制图形的代码，用 fig 开头 测试代码：test 开头 其余需要特殊定义的代码：根据功能，返回布尔值的用 is 开头，如判断碰撞函数 isCollided；返回其他数据的用 get 开头 文件说明注释 # 除了上面命名规范里面提及的一些常见类型的文件不用添加参数外，即 data，test，fig，main 这四个，其余的都应该在文件内添加说明性注释；\n简明而清晰的文件说明注释：文件说明一般在文件开头，包含函数功能概述、函数接受参数、函数输出参数三个主要部分\n实在不会写，用 AI 帮助就行；\n内部变量命名 # 统一的固定参数 # 所有固定的参数全部都放置到根目录下的一个 config.m 文件中，进行统一管理，每个参数后面请添加注释说明，例如：\nlearningRate = 0.001; % 学习率 batchSize = 32; % 每批输入的数据量 numEpochs = 100; % 迭代次数 在其他代码中引用这个配置文件只需要加入代码：\nrun(\u0026#39;config.m\u0026#39;); 尽管参数被转移到了其他地方但是 VS Code 仍然能够进行自动检测并给出补全提示！ 函数内部使用的参数 # 函数内部所有使用的变量都应该在主程序开始之前明确定义，并在变量后添加简要的中文注释；\n如果有一些表达相同含义的参数在多个文件中使用，请使用统一的命名，尤其是 AI 生成的代码，请在 VS Code 中使用 F2 进行重命名 代码格式化 # 代码的格式化主要通过官方的 MATLAB 插件来执行。安装插件之后，按快捷键 Shift+Alt+F 即可格式化代码。\nGit 版本控制 # 这里需要新建一个 GitHub 代码仓库来存放整个项目文件。尽管使用了 Live Server 插件能够更加快速地执行代码协同，但是仍然需要在一些重要的开发结点进行提交保存，保留代码的回滚能力。\n所有的 Git 版本控制操作都在代码负责人的电脑上操作，其他辅助编程人员使用 Live Server 插件进行更实时的代码协同。\n本地 commit 保存小改进 push 操作以小题为单位进行，保存重大进展 代码执行 # 感谢官方对于 MATLAB 插件的更新支持，最新的插件能够在 VS Code 编辑器中直接运和调试行代码。尽管有些限制，但瑕不掩瑜。\n其他 # AI 指令集 # 由于生成式 AI 的代码规范可能与项目不同，因此如果有生成一整个文件的需求，请在你的指令之前添加如下的代码规范指令：\n你是一个成熟而规范的MATLAB程序员，在正确实现用户目标的前提下，遵守以下代码规范： 1. 简明而清晰的文件说明注释：文件说明一般在文件开头，包含函数功能概述、函数接受参数、函数输出参数三个主要部分 2. 函数内部的变量命名应当简明易读 3. 函数内部所有使用的变量都应该在主程序开始之前明确定义，并在变量后添加简要的中文注释 用户指令： 配套样例项目 # 为了能够快速、规范地启动工程项目，我创建了一个样例项目，里面包含了所有上文提及的代码规范，可以直接对这个项目进行修改，省去了记忆的苦恼😄\n代码技巧 # 并行运行 MATLAB 能够支持多线程计算，仅需将一般的 for 循环改写为 parfor 即可 parfor 函数的执行要求十分严格，具体参阅官方说明 大型表格处理 # 模型计算的输出往往是一个超大型数据表格，并且存储在 .mat 文件中，难以进行数据的快速提取。\n直接编写了一个简单的 Python 脚本来进行大型表格数据的提取操作：数据提取器\n同时配合 LaTeX 在线表格编辑网站，能够实现在论文中快速插入表格数据。\n","date":"2025-01-16","externalUrl":null,"permalink":"/blog/code-collaboration-scheme/","section":"Blogs","summary":"\u003cp\u003e\n\n\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  总结 CUMCM2024 比赛经验，针对数学建模国赛 A 题和MATLAB改进的代码协同方案\n\u003c/div\u003e\n\u003c/p\u003e","title":"代码协同方案","type":"blog"},{"content":" MySQL 安装部署流程 + 简明语法 CookBook + 学习笔记 信息源 # SQL教程 - 廖雪峰的官方网站 非常非常亲民的 MySQL 教程网站，内置了一个网页版的数据库，方便新手同志们直观了解 MySQL数据库的操作，对于 SQL 的整个背景也有简洁但必要的表述。 安装 MySQL # 安装 MySQL 最简单的方法就是通过 Docker Desktop 来操作；只需要两步就能够完成\n命令行中运行：\ndocker pull mysql 命令行启动MySQL # 初始化 SQL 并运行：\ndocker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password -v /Users/liaoxuefeng/mysql-data:/var/lib/mysql mysql 参数解释：\n参数 含义 -d 表示后台运行 --name 表示容器的名字，不输入 Docker 会自动选择一个名字 -p 3306:3306 表示把容器的端口 3306 映射到本机，这样可以在本机通过 3306 端口连接 MySQL -e MYSQL_ROOT_PASSWORD=password 表示传入一个环境变量，作为root的口令，这里设置的口令是 password，不输入此项则会自动生成一个口令，需要查看日志才能知道口令，建议设置 -v /path:/var/lib/mysql 表示将本地目录映射到容器目录 /var/lib/mysql 作为 MySQL 数据库存放的位置，需要将 /path 改为你的电脑上的实际目录 mysql 告诉 Docker 你要运行的镜像的名称 使用 Docker 运行 MySQL 时，任何时候都可以删除 MySQL 容器并重新运行；如果删除了本地映射的目录，重新运行就相当于一个全新的 MySQL ； docker-compose启动MySQL # 创建 docker-compose.yml 文件如下：\nservices: mysql: image: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: password volumes: - ../data:/var/lib/mysql restart: unless-stopped 运行 docker-compose build up -d 来启动服务\nMySQL 基础语法 # 查询 # 注释语法：\n-- 这是一条注释 基本查询语法：\nSELECT * FROM \u0026lt;表名\u0026gt;; 条件查询：\nSELECT * FROM \u0026lt;表名\u0026gt; WHERE \u0026lt;条件表达式\u0026gt;; 其中条件表达式内部还可以使用各种逻辑运算关键词，如：AND，NOT，OR\n投影查询：\nSELECT \u0026lt;列1\u0026gt;, \u0026lt;列2\u0026gt;, \u0026lt;列3\u0026gt; FROM \u0026lt;表名\u0026gt;; SELECT \u0026lt;列1\u0026gt; 别名1, \u0026lt;列2\u0026gt; 别名2, \u0026lt;列3\u0026gt; 别名3 FROM \u0026lt;表名\u0026gt;; 排序：\n-- 按score从低到高: SELECT id, name, gender, score FROM students ORDER BY score; -- 按score从高到低: SELECT id, name, gender, score FROM students ORDER BY score DESC; -- 按score, gender排序: SELECT id, name, gender, score FROM students ORDER BY score DESC, gender; -- 带WHERE条件的ORDER BY: SELECT id, name, gender, score FROM students WHERE class_id = 1 ORDER BY score DESC; 分页查询：\n-- 查询第1页: SELECT id, name, gender, score FROM students ORDER BY score DESC LIMIT 3 OFFSET 0; -- 从第0条记录开始查，往后查最多3条，也可以不足3条 聚合查询，利用 MySQL 中的聚合函数来查询：\n-- 使用聚合查询, 查询记录的总条数: SELECT COUNT(*) FROM students; -- 使用聚合查询并设置结果集的列名为num: SELECT COUNT(*) num FROM students; -- 使用聚合查询并设置WHERE条件: SELECT COUNT(*) boys FROM students WHERE gender = \u0026#39;M\u0026#39;; 虽然 COUNT(*) 的结果是一个标量，但是返回仍然是一个二维表格，只是表格只有一行一列 另外还有一些常用的聚合函数：MAX()，MIN()，AVG()，SUM() 等，与 COUNT() 类似\n分组聚合查询：\n-- 按class_id分组进行聚合查询, 类似于for循环: SELECT COUNT(*) num FROM students GROUP BY class_id; -- 注意这里没有选中class_id因此最后的结果表格没有id -- 按class_id分组, 并显示class_id: SELECT class_id, COUNT(*) num FROM students GROUP BY class_id; -- 多个分组标准, 例如按class_id, gender分组: SELECT class_id, gender, COUNT(*) num FROM students GROUP BY class_id, gender; 多表查询(笛卡尔查询)：\n-- FROM students, classes: SELECT * FROM students, classes; -- 设置别名，同名列通过.操作服进行区分: SELECT students.id sid, students.name, students.gender, students.score, classes.id cid, classes.name cname FROM students, classes; -- 设置报个别名, 更清爽一点点: SELECT s.id sid, s.name, s.gender, s.score, c.id cid, c.name cname FROM students s, classes c; 多表查询的返回依然是一个二维数据表，但是这个数据表是通过笛卡尔积的形式组织的，因此也叫笛卡尔查询\n连接查询，类似于多表查询，但是两个表之间的组织关系不是通过笛卡尔积进行，而是选取一个为主表，将附表的内容进行连接：\n内连接，只有一种，修饰语为 INNER： -- 选出所有学生，同时返回班级名称: SELECT s.id, s.name, s.class_id, c.name class_name, s.gender, s.score FROM students s INNER JOIN classes c ON s.class_id = c.id; 外连接，有三种，修饰语为 RIGHT，LEFT，FULL： -- 使用RIGHT OUTER JOIN: SELECT s.id, s.name, s.class_id, c.name class_name, s.gender, s.score FROM students s RIGHT OUTER JOIN classes c ON s.class_id = c.id; 理解方法：通过集合的方式来理解\n-- 这里面tableA是主表, 也叫左表; tableB同理 SELECT ... FROM tableA ??? JOIN tableB ON tableA.column1 = tableB.column2; 修改 # 插入语法： -- 添加一条新记录: INSERT INTO students (class_id, name, gender, score) VALUES (2, \u0026#39;大牛\u0026#39;, \u0026#39;M\u0026#39;, 80); -- 一次性添加多条新记录: INSERT INTO students (class_id, name, gender, score) VALUES (1, \u0026#39;大宝\u0026#39;, \u0026#39;M\u0026#39;, 87), (2, \u0026#39;二宝\u0026#39;, \u0026#39;M\u0026#39;, 81), (3, \u0026#39;三宝\u0026#39;, \u0026#39;M\u0026#39;, 83); 更新： -- 更新id=1的记录: UPDATE students SET name=\u0026#39;大牛\u0026#39;, score=66 WHERE id=1; -- 更新score\u0026lt;80的记录: UPDATE students SET score=score+10 WHERE score\u0026lt;80; -- 更新id=999的记录, 没有匹配的记录所以什么都不会做: UPDATE students SET score=100 WHERE id=999; -- 不带WHERE语句的更新会作用在整张表上 UPDATE students SET score=60; 删除： -- 删除id=1的记录: DELETE FROM students WHERE id=1; -- 不带WHERE的删除操作会作用于整张表 DELETE FROM students; 创建 # 建库： CREATE DATABASE your_db_name -- 数据库名称 CHARACTER SET utf8mb4 -- 数据库字符集 COLLATE utf8mb4_unicode_ci; -- 指定排序规则 建表： CREATE TABLE 表名 ( 列名1 数据类型 约束, 列名2 数据类型 约束, 列名3 数据类型 约束, ... PRIMARY KEY (主键列名) ); -- 具体的一个用户表 CREATE TABLE users ( id INT AUTO_INCREMENT, username VARCHAR(50) NOT NULL UNIQUE, email VARCHAR(100) NOT NULL UNIQUE, password VARCHAR(255) NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (id) ); 触发器： CREATE TRIGGER trigger_name BEFORE INSERT ON orders FOR EACH ROW BEGIN SET NEW.order_time = NOW(); END; ","date":"2025-01-15","externalUrl":null,"permalink":"/blog/mysql-basics/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  MySQL 安装部署流程 + 简明语法 CookBook + 学习笔记\n\u003c/div\u003e\n\n\n\n\u003ch3 class=\"relative group\"\u003e信息源 \n    \u003cdiv id=\"%E4%BF%A1%E6%81%AF%E6%BA%90\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%BF%A1%E6%81%AF%E6%BA%90\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://liaoxuefeng.com/books/sql/introduction/index.html\" target=\"_blank\"\u003eSQL教程 - 廖雪峰的官方网站\u003c/a\u003e\n非常非常亲民的 MySQL 教程网站，内置了一个网页版的数据库，方便新手同志们直观了解 MySQL数据库的操作，对于 SQL 的整个背景也有简洁但必要的表述。\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ch3 class=\"relative group\"\u003e安装 MySQL \n    \u003cdiv id=\"%E5%AE%89%E8%A3%85-mysql\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%AE%89%E8%A3%85-mysql\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e安装 MySQL 最简单的方法就是通过 Docker Desktop 来操作；只需要两步就能够完成\u003c/p\u003e","title":"MySQL基础","type":"blog"},{"content":" 熟悉项目分析流程，是一个练手性质的分析报告 我在初步完成自己的小插件之后才发现：笔记转博客这个领域似乎没有一个一键式解决方案，为此我写了这篇文章来分析是否要创建一个新的项目来填补这个空白。\n项目没有优劣之分，只有合适与否，这篇文章中涉及的评价标准都是围绕是否符合博客网页要求进行的，因此可能有些项目并不适合做博客网页，但是这丝毫不影响项目本身的价值。\n领域定义 # 在所有分析开始之前，需要对于笔记转博客这个领域有一个清晰的界定。\n笔记：此处的笔记特指 Obsidian 中的笔记，含有 Obsidian Flavored Markdown，这对笔记向网页转换的过程提出了不小的要求。\n博客：博客，顾名思义是一种获得流量的手段，创作者花费时间创作笔记，然后经由转换软件，生成排版精美、功能丰富的博客网页\n评价细则如下：\n隐私方面\n是否本地运行 是否开源 使用舒适性\n与 Obsidian 语法的适配程度 服务部署复杂程度 帮助文档撰写详细程度 个性化调整复杂设置 网页功能完整性\n默认配套网页的核心功能是否齐全（搜索、日间/夜间模式等） 默认网页美观程度 是否支持 SEO 对 Obsidian 原生语法的转化效果是否生硬（例如：展示性链接内是否存在不能翻译的代码块、是否舍弃部分 Obsidian 语法特性等） 项目概述 # 在我的设想中，这个项目的功能就是构建一个 Obsidian 插件，实现从 Obsidian 笔记到 Hugo 博客网页的无缝导出，支持 Obsidian 的所有基本核心功能。\n成效：大大降低了创建博客网页的成本，只要能够使用 Obsidian 就能够拥有属于自己的博客网页。\n市场和用户可行性分析 # 市场需求分析 # 概述 # 基本需求：搭建个人网站并持续输出的需求，包括自我提升、自我表达、创造独特全面的个人能力展示平台（对接企业招聘）等等\n目标用户群：重度 Obsidian 用户且有分享笔记的需求；想要搭建个人博客但是因为技术难度而放弃的知识创作者\n相关数据 # Flowershow：截至 2024 年 10 月插件下载量为 3355；截至 2025 年 1 月插件下载量为 4594，同时最高下载量的插件有 3211992 的下载量； Quartz 截至 2025 年 1 月收获 GitHub start 数量为 7.7k 已有方案 # Quartz # 推荐指数：❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥\n介绍 # Quartz 是一个将 Obsidian 笔记转化为网页的工具集。Quartz 的最新版本是 v4 版本，相较于 v3 版本， v4 版本从底层完全重构了代码，去除了对于 Hugo 的依赖，优化了用户自定义的体验。目前 v4 版本主要使用 TypeScript 构建，原本 hugo 的 template 也改用 JSX 替换。\n因此，现在的 Quartz 几乎可以说和 Hugo 没什么关系了，但是目前国内的很多信息还是宣传 Quartz 的底层是 Hugo\n官方样例网站：Welcome to Quartz 4\n评述 # 优点\n功能非常非常完整 所有相关套件中唯一成功解决了展示性 wiki 链接的一个 配套文档很详细 缺点\n几乎没有缺点，唯一一个值得提点的地方就是没有中文的文档 总结：非常优秀的项目，所有在 Obsidian 内显示的样式就是网页中显示的样式，确实也收获了所有现成方案中最多的 GitHub start 数量\nFlowershow # 推荐指数：❤️‍🔥❤️‍🔥❤️‍🔥❤️‍🔥🩶\n介绍 # Flowershow 是一个基于 Obsidian 的整体发布服务，它可以将你的 Obsidian 笔记按照目录结构，转换为一个在线的数字花园网站。而 Vercel 是一个针对前端的云服务，它实现了通过 Github 免服务器快速部署前端服务，每次提交内容都会触发一次自动部署。Flowershow 的官方部署文件中需要使用 Vercel，国内使用可以考虑 Netlify 替换\n参考教程：Flowershow：免费的 Obsidian 笔记发布服务，实现你的数字花园网站\n主观上来讲，这个项目的主创团队是一支很有激情和使命感的队伍，关于 Flowershow 的简介里面包含了很多主创团队的核心理念。\n客观上来讲，Flowershow 的项目定位非常准确，就是一个基于 Obsidian 的博客网页生成平台，因此最终效果从前端和后端两个角度来说都是非常好的。\n评述 # 优点\n定位清晰，工作流程简洁明了 功能支持较为全面 背后有专业的团队进行运维 允许高度的自定义，适合喜欢个性化的创作者 缺点(一下信息均来自 2025 年 1 月)\n部分 Obsidian 的功能并没有处理，例如展示性的 wiki 链接并没有处理，至少介绍文档中跳过了这部分内容 仔细翻找了网站并没有发现反向链接的说明，但是首页信息显示能够支持反向链接 总结：总体上项目做的还是挺好，但是项目还在进行中，部分细节并不到位，对于 Obsidian 语法支持没有那么高要求的创作者就可以采用这个方案了\n官方发布 # 推荐指数：❤️‍🔥❤️‍🔥❤️‍🔥🩶🩶\n介绍 # 下面是几个样例网站：\nObsidian中文教程一个中文教程网站，使用了 Obsidian 官方的发布服务，里面里面可以体现一些功能，例如对于展示性链接的处理 Digital 3D Garden 有深度的前端界面自定义 mister chad 非常简洁工整的小站，内容很充实 Discrete Structures for Computer Science 神似官方的朴素风格 评述 # 优势\n官方发布的网页对于 Obsidian 内部表达的适配效果是一流的，Obsidian 内部所有的功能都能够成功在网页中展示；但是不清楚插件功能如何在网页中展示 有持续的维护服务，能够第一时间适配 Obsidian 的更新 支持高度的个性化设置，如果具有充足的代码经验，可以开发出相当精美的网页；同时还有大量的其他开发者开发的主题 隐私设置，网站能够设置密码，控制访问人员，可能用于企业内部文档管理 有 SEO 加持和移动平台适配，流量可能会更大一些 劣势\n每个月需要支付 8 美元，由于个人网站的流量相当小需要长期持有才会有明显的收益，因此这笔支出不是小数目，这是官方发布服务的致命缺陷 停止付费之后网页将不能被访问 国内的服务支持不佳，流量受限 总结：官方发布适合资金充裕，并且对于网站的自定义开发没有那么高需求的用户。\nDigital Garden # 推荐指数：❤️‍🔥❤️‍🔥❤️‍🔥🩶🩶\n介绍 # Digital Garden 是一款 Obsidian 插件，可以将笔记导出为网页并托管在 GitHub 上，然后再使用 Vercel 或者 Netlify 进行网页的发布。具体操作教程见 Digital Garden教程\n这里是几个样例网站：\nDigital Garden 官方样例 Aaron Youn 民间自制 John\u0026rsquo;s Digital Galaxy 非常丰富的内容，可以详细展示所有 Digital Garden 涉及的特性，特别是展示性链接循环嵌套 评述 # 优点\n功能支持较为全面 支持 Obsidian 的主题迁移 缺点\n对于中文路径不友好 网页界面自定义需要直接处理网页源码，即 HTML JavsScript CSS，并且默认配套的界面不太好看 总结：工作流程非常的简单，功能支持相当的全面，作为插件嵌入 Obsidian 更加轻便。虽然界面美化需要花些功夫，但如果对于界面美观与否并不在意，可以直接上手。\nPerlite # 推荐指数：❤️‍🔥❤️‍🔥🩶🩶🩶\n介绍 # Perlite 是一款网页版 Obsidian 文件阅读器，是 Obsidian 官方发布服务的开源平替。Obsidian Publish的开源替代品Perlite 这是微信公众号上的一个教程文本。\n这款开源平替最大的特点就是：其网页 UI 几乎和 Obsidian 的界面完全相同，提供近乎原生的浏览服务。\n评述 # 优点\n很好地支持几乎所有的 Obsidian 的功能 原生经典界面，给用户提供熟悉感 缺点\n不算是一个博客页面，官方对于项目的定位也确实不是博客网页而是一个“文件阅读器” 需要使用 Docker，启动缓慢，不如插件的那样的轻巧简洁的体验感 总结：Perlite 的定位决定了其并不适合直接用作展示性的博客页面，其界面实在是有点单调，对于访客的视觉吸引力其实并不强。更适合于作为一款网页版的 Obsidian，在上面进行文件的编辑可以更加专注，效果也更好\njekyll+Netlify+GitHub Pages # 推荐指数：❤️‍🔥❤️‍🔥🩶🩶🩶\n介绍 # 方法流程来源于 obsidian 目前最完美的免费发布方案 渐进式教程，教程内容很详细，既有基本的对比评价，也有详细的指导教程\n这是作者构建的例子网站：oldwinterの数字花园\n评述 # 优点\n配置简单 允许高度自定义 缺点\n部分 Obsidian 特色语法不支持，比如 callout 语法 不支持暗色模式 不支持搜索 总结：整体上是一个非常好的 Obsidian 转换为博客网页的实践，但是因为部分核心功能缺失因此并不适合想要完整的网页体验的创作者\nTiddlyWiki # 推荐指数：❤️‍🔥🩶🩶🩶🩶\n介绍 # TiddlyWiki 是一个历史悠久的笔记框架，至今依然有很强的生命力，许多开发者活跃在这个领域中。国内也有相关站点可以供访问：太微舞，以及配套教程：[太微中文教程](https://tw-cn.netlify.app /)；国内的开发者在近年推出的衍生版本 TidGi（太记）;\n利用Tiddlywiki发布Obsidian库这是一个将 Obsidian 发布到 TiddlyWiki 的流程性教程\n此外还有一些散落在互联网上的介绍和样例：\n了不起的“活笔记”系统：TiddlyWiki（太微笔记） - 少数派非常好的一片笔记文章，真正意义上的一文秒懂 TiddlyWiki；文章作者自己的笔记网站：MRIWiki.cn — 磁共振百科知识太微笔记 [太微中文教程](https://tw-cn.netlify.app /)教程本身就是利用 TiddlyWiki 编写的，可以查看 TiddlyWiki 的使用效果 评述 # 优势\n极致的简洁性与轻量化，可以说没有任何其他的个人网页比它更简单！ 经过历史的筛选，拥有广泛的用户群体 成熟的国内服务，不需要科学上网就能够访问 劣势\n由于极致的简洁，导致网页看上去可能有点原始 不算完全的个人博客，其完全不迎合主流搜索引擎，直接靠搜索根本无法访问，难以获得流量（也是我撰写这篇文章之前从未听闻的原因😢） 总结：TiddlyWiki 的确是一个非常简洁和轻量化的笔记框架，这也吸引了很多的用户；但也正是因为其定位并非博客网页，所以导致用户的内容封闭在 TiddlyWiki 社区内部，甚至是封闭在创作者自己手中，无法转化为流量，并不适合有流量需求的创作者，而更加适合作为一个简单纯粹的笔记存储库\n结论 # 在经过完整的分析之前，我并不了解笔记转博客这个领域内部的实际情况，因此萌生了想做一个简化插件项目的想法💡\n但是经过系统性的调查研究，我必须承认 Quartz 确实是这个领域内出类拔萃的项目，无论从 Obsidian 语法适配性、配置流程便捷程度、前端配套界面美观程度、前端界面自定义便捷程度、后端撰写博客便捷程度等等各种方面，几乎都没有上升空间了。\n因此也就不需要我再去启动一个项目来做重复的事情了。在这里向所有笔记转博客领域内的相关项目的开发团队致敬🫡不管是否在文章中提及。\n项目没有优劣之分，只有合适与否，这篇文章中涉及的评价标准都是围绕是否符合博客网页要求进行的，因此可能有些项目并不适合做博客网页，但是这丝毫不影响项目本身的价值。\n向开源先锋致敬🫡🫡🫡\n","date":"2025-01-10","externalUrl":null,"permalink":"/blog/note-to-blog-report/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  熟悉项目分析流程，是一个练手性质的分析报告\n\u003c/div\u003e\n\n\u003cp\u003e我在初步完成自己的\u003ca href=\"https://morethan987.github.io/blog/plugin-writing-experience/\"\u003e小插件\u003c/a\u003e之后才发现：\u003cstrong\u003e笔记转博客\u003c/strong\u003e这个领域似乎没有一个一键式解决方案，为此我写了这篇文章来分析是否要创建一个新的项目来填补这个空白。\u003c/p\u003e","title":"笔记转博客项目分析报告","type":"blog"},{"content":" 博客网站折腾日志，从手搓到 Hugo 的曲折经历。 为什么 Hugo # 最初也只是因为偶然间听说了 Hugo 可以做网页，并且听说编译静态页面非常高效，于是才去搜集的相关资料——据说 Hugo 是世界上最快的静态页面生成器，官方网站也是这么写的。\n当然，口说无凭，下面就是我初次本地编译运行 Hugo 得到的输出，即在完全没有 public 文件夹的情况下的输出：\nZH-CN EN Pages 53 51 Paginator pages 0 0 Non-page files 13 13 Static files 7 7 Processed images 3 0 Aliases 18 17 Cleaned 0 0 Built in 872 ms\n中英文总共 104 个网页页面花费时间 0.872 秒，并且包含构建本地服务的时间，这个速度确实没什么好挑剔的了。并且本地的服务能够实时监听源代码的改动并进行增量重构，这个增量重构的时间取决于改动的多少，一般在 0.03 秒左右。\n我并没有用别的网页生成工具搭建过博客，因此无法给出其他生成器的实际生成速度 参考引用 # 下面是我在搭建博客的过程中所用到的所有资源链接：\n莱特雷-letere 这是一位博主的网页，也是用 Hugo 搭建的，里面同时也有很多其他的网页工具的教程；这是他在 B 站上发布的系列视频教程 Blowfish 这是我使用的一款 Hugo 主题，文档写的相当的好，真的没见过如此耐心的作者。 Hugo官方网页 Hugo Themes 部署全流程 # 搭建 Hugo 环境 # 这一部分在那位博主的网页和视频教程中都有非常详细的讲解，不喜欢看文字的可以去看视频😝\n说实话，Hugo 的环境搭建真的是我见过的最简单的，没有之一。你只需要到 Hugo官方网页去把 Hugo 下载下来，然后存放到合适的文件夹里面，然后解压就完成了，解压之后的文件夹内也只有一个 hugo.exe 文件，简直不要太简单。\nHugo 真的是太方便了，我曾经尝试过 Hexo 但是 Node.js 的配置就把我拒之门外了，到现在我也不知道为什么会编译报错😢 稍微需要那么一点点🤏难度的工作其实就是把 hugo.exe 所在的目录添加到环境变量里面去。\n生成模版系统 # 在 hugo.exe 的目录中打开终端，然后输入命令 hugo new site your-site-name，然后就可以看到一个新的文件夹📂出现在了当前文件夹里面。\n模板系统听着很高级，其实就是在你的 hugo.exe 的同级目录下面建一个文件夹，但是里面的所有文件夹都有特殊的含义，不能随便改动。\n名称 含义 asset 存放网站结构用到的图片，图标等资产 config 网站配置文件夹（初始时可能没有，有些主题需要） hugo.toml 网站配置文件之一 content 所有内容都在这里面 public 是编译后生成的完整网页，一开始没有 themes 存放你的网站主题 主题配置基本操作 # Hugo 的网站主题很多，具体参考 Hugo Themes 你可以选一款你喜欢的主题，然后下载之后就放在 themes 文件夹里面就行。这一部分文字描述非常抽象，见视频教程\n这里有一个重点是：基本上每一个主题都会配置一个样例网站，一般在文件夹 exampleSite 里面，如果实在不想跟着网站文档自己配置，直接用这个样例网站的配置也是可以的。\n每一个不同的主题基本配置完成之后都要进行个性化配置。这里我重点推荐重点推荐一下我使用的主题 Blowfish 相当好的一款主题，向作者致敬🫡\nBlowfish 主题 # Blowfish 官方文档上面已经有了非常非常详细的指导文档，不再过多赘述。任何一个多余的字都是对于如此详细的指导文档的不尊重🫡\n我这里简要说明一些可能出现的问题，下面的内容你可能需要仔细阅读官方文档之后才能明白其中含义🤔\n在 params.homepage.showRecent = false 的情况下，为什么还会显示\u0026quot;最近文章\u0026quot;？ 如果遇到这个问题，说明你跟我一样懒惰🤪直接套用了 exampleSite 的代码。这是因为控制主页面的接口不止这一个，还有一个在 layouts\\partials\\home\\custom.html 文件中。\n如果你不介意那么直接忽略就行，如果你介意（跟我一样🤪），那就把文件中的下面的代码注释掉👇\n\u0026lt;section\u0026gt; {{ partial \u0026#34;recent-articles-demo.html\u0026#34; . }} \u0026lt;/section\u0026gt; 为什么我使用 svg 格式的 logo 无法完成(日间/夜间)模式的切换？ 这是我发现的一个 bug，已经给主题作者推送我改进的代码了，详见代码改进或 SVG 支持\n为什么浏览器窗口上的小图标一直都是 blowfish，即使改换了 logo 也不行？ 官方文档其实是有写的，但藏的太深了，见局部模板(Partials) · Blowfish\n说实话，官方文档写的真的好👍一套完整流程走下来竟然只有这么点不太容易理解的错误😋\n配套插件 # 我日常习惯使用 Obsidian 来写文章，由于 Obsidian 的格式与 Blowfish 的格式还是有较为明显的区别，二者的格式转换非常麻烦🤔\n在查询了一圈之后，发现根本就没有适合的插件！于是，我自己开发了一个插件：Hugo-Blowfish-Exporter\n虽然插件功能很简单，但是也已经覆盖了我自己绝大部分的使用功能，包括：\n- callout（支持所有官方的 callout 名称，需要新增图标）\n- 内联数学公式（Blowfish 支持块级公式）\n- mermaid（支持 mermaid 图表）\n- 图片插入（能够自动导出图片）\n- Wiki链接导出（并不支持展示性链接😢）\n非展示性链接简单处理为网页超链接形式\n展示性链接较为复杂：需要覆写 Blowfish 主题的源代码，通过 mdimporter 这个 shortcode 来进行文件注入；同时为了方便链接，每一个文件都需要设置 slug 属性来标记网站中存放 markdown 文件的文件夹\n对于主题源代码的覆写详见 mdimporter 以及用于去除注入文件开头元数据的 stripFrontMatter；覆写目录参考 GitHub 上的配置\n这个插件也是投入了我巨大的精力，虽然也只有几天时间🤔但是那几天还是挺累的😵‍💫\n如果这个插件帮助了你，还请转发分享；如果你对于这个插件的功能不满意，你也可以在 GitHub 上向我提交 Issue🫡或者熟悉代码的朋友可以直接把源码拿去修改，注释很完整，代码比较规范🤗\n如果你能把你亲自修改升级的代码也分享给我（在 GitHub 上提交 Pull Request）那更是万分感谢！☺️\n写在最后 # 一个博客网站的搭建只是万里长征的第一步，真正困难的还是博客内容的填充。\n正如我在一次写插件的经历中所写，很多个人博客网站从一开始的火热到最终的沉寂可能只需要短短一年的时间。\n在这个生活节奏越来越快的时代，无意义、无效率的事情大多都会向高效让步，曾经的初心与梦想往往会向生活妥协。我自己也早已经没有了当初的热情，行为方式上也更加的像一个真正的成年人。\n但是我仍然是有些不甘心，这个网站就是一种抗争吧，我会尽力维护下去，这也是我写插件方便我更新博客的目的所在。\n因此希望这篇教程所提供的内容能够帮助到正在准备搭建自己的博客网站的你，你我共勉🫡\n","date":"2025-01-07","externalUrl":null,"permalink":"/blog/hugo-blog/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  博客网站折腾日志，从手搓到 Hugo 的曲折经历。\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e为什么 Hugo \n    \u003cdiv id=\"%E4%B8%BA%E4%BB%80%E4%B9%88-hugo\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88-hugo\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e最初也只是因为偶然间听说了 Hugo 可以做网页，并且听说编译静态页面非常高效，于是才去搜集的相关资料——据说 Hugo 是\u003cstrong\u003e世界上最快\u003c/strong\u003e的静态页面生成器，官方网站也是这么写的。\u003c/p\u003e","title":"Hugo博客搭建","type":"blog"},{"content":" 记一次写插件的经历，以及从中收获的一些感想。 缘由 # 事情起源于我这个博客网站。我在微信公众号上偶然间浏览到了关于用 Hugo 建立博客网站的信息，正好我也想翻新一下我那简陋的小网站。我原来的小网站非常非常的原始，整个写作流程都需要在 HTML JS 和 CSS 之间狼狈地切换。并且我非常崇拜的大佬 Lilian Weng 的 博客 也是用 Hugo 搭建的，这也更加坚定了我换底层的决心。\n于是我便迅速开始了对于 Hugo 的接触。\n结果真的出乎意料！我原来的网页花费了我将近一个月的时间，用 Hugo 竟然不到一上午就搞定了。更令我惊讶的是 Hugo 作为一个用 Go 编写的程序，其竟然不需要用户搭建 Go 环境！😮\n同时，我也发现了一个非常用心的 Hugo 主题 Blowfish 。这真的是我见过的文档配置最为详细的一个项目，没有之一(๑•̀ㅂ•́)و✧\n在 Hugo 和 Blowfish 的强力驱动下，我的小网站竟然变得像模像样的了。当然请原谅我并不擅长美化页面，所以我就直接套用了 Blowfish 官方网站的界面设置，因为我觉得任何的改动都会让这个精美的页面变得不协调。\n说实话，做完这一切我并没有什么特别的情绪波动，除了敬佩 Hugo 和 Blowfish 的作者们强悍的编码能力。\n直到我想将我在 Obsidian 中大量的笔记都上传到这个博客网站。\n原创的苦涩 # 我发现在 Obsidian 中并没有现成的可以直接适配 Blowfish 主题的格式转换插件。于是在前面那“愉快体验”的助推下，我决定自己写一个插件！(😄虽然过一会儿就笑不出来了😢)\n后面的经历实在是没什么好描述的，一遍又一遍地在网页之间来回切换，不停地搜索各种API文档，与AI机器人的沟通也从未停止。经过了无数次修改，我终于写出来了一个再简单不过的东西：识别文档中的固定模式然后进行内容替换。\n令人哭笑不得，相比于创建网站那短短的几个小时，我这将近四十个小时的工作几乎可以说微不足道。有那么一瞬间我真的想直接删掉我那几百行的代码。\n是的，就这么一个简单的插件就让我心力交瘁，疲惫不堪。我亲口品尝到了原创的苦涩。\n现在让我回头看 Hugo 和 Blowfish 我感受到了深深的震撼，如此复杂的功能实现不知道要消耗多少精力。如果说他们的工作都是付费的，那我还能心安理得地接受如此的工作量。然而他们都是开源的，有没有收入全凭用户喜好。\n我看着 Blowfish 作者那停滞在2024年3月的博客，我陷入了沉思。\n情怀与理想 # 我猜想 Blowfish 的作者肯定是因为别的什么事情暂时放缓了对于这个主题的维护，毕竟这个项目并没有带来多少实际的收入。\n突然之间我回想起了之前那些被我忽略的现象，一些 GitHub 达人主页上满满的绿色瓷砖慢慢变得稀疏，最后消失。在这平静如水的变化之下，或许是一个人生活的转变。或因生活工作忙碌，或因开发动力逐渐衰减，但最后原本的热血初心都淹没在了寂静之中。我无法阻止这样的现象发生，但我理解这背后的原因。\n开源是情怀，但是情怀不能当饭吃。人总是要活在当下的。\n我想起来 bilibili 上的一位博主 码农高天 ，一位 Python 的核心开发者，用幽默诙谐的段子吐槽开源人的悲惨待遇。他那年纪轻轻就已经花白的头发让人不经感慨“生活真是不容易啊”——写了大半辈子的代码，现在竟然还是待业在家，靠着发发视频赚点外快。\n写在最后 # 人生不如意，十之八九。我又一次看着那四十多小时的工作成功，笑着摇了摇头。\n写完这一句，我就睡觉去了，现在是2025年1月6日凌晨1:48，明天还有英语的期末考试，还没复习呢。\n我看着这篇博客，又一次笑着摇了摇头。\n这就是生活。\n","date":"2025-01-06","externalUrl":null,"permalink":"/blog/plugin-writing-experience/","section":"Blogs","summary":"\u003cdiv class=\"lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl\"\u003e\n  记一次写插件的经历，以及从中收获的一些感想。\n\u003c/div\u003e\n\n\n\n\u003ch3 class=\"relative group\"\u003e缘由 \n    \u003cdiv id=\"%E7%BC%98%E7%94%B1\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%BC%98%E7%94%B1\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e事情起源于我这个博客网站。我在微信公众号上偶然间浏览到了关于用 \u003ccode\u003eHugo\u003c/code\u003e 建立博客网站的信息，正好我也想翻新一下我那简陋的小网站。我原来的小网站非常非常的原始，整个写作流程都需要在 \u003ccode\u003eHTML\u003c/code\u003e \u003ccode\u003eJS\u003c/code\u003e 和 \u003ccode\u003eCSS\u003c/code\u003e 之间狼狈地切换。并且我非常崇拜的大佬 \u003ccode\u003eLilian Weng\u003c/code\u003e 的 \u003ca href=\"https://lilianweng.github.io/\" target=\"_blank\"\u003e博客\u003c/a\u003e 也是用 \u003ccode\u003eHugo\u003c/code\u003e 搭建的，这也更加坚定了我换底层的决心。\u003c/p\u003e","title":"一次写插件经历","type":"blog"},{"content":" 莫拉维克悖论 # 高水平的推理需要相对较少的计算资源，而低水平的感知和运动技能则需要大量的计算资源。\n这个现象意味着计算机和机器人在处理复杂逻辑和数学问题时相对容易，而在执行诸如行走、抓取和视觉识别等基本感知和运动任务时却非常困难。\n分析 # 低水平的感知和运动技能从主观上来说非常简单，但从计算理论的角度来说却非常复杂。\n高级任务：这个名词本身就十分主观，\u0026ldquo;高级\u0026quot;一词其实等价于\u0026quot;对人类来说困难\u0026rdquo;。然而这些所谓困难的任务却大多都是多项式时间可解的，这意味着从自身性质上来说，高级任务所涉及的问题并不复杂。\n低级任务：其包含的问题大多是 NP 难甚至是 PSPACE 难的，从问题本身的性质来说，这类问题相当复杂。\n人类能够轻而易举地解决低级任务源于进化过程中持续进行的优化：经历了漫长的岁月人类才获得了高效正确处理低级任务的能力；而产生处理高级任务的能力花费的时间相对来说很少。\n这种反常悖论似乎来源于知识的可概括性，某些知识具有良好的可压缩性，但另外一些则不具有。有一个更加准确的概念叫做计算可约性\n一个很简单的例子：考试，从逻辑上来说全部都是基于最基本的知识推理而来的对吧？讲道理，考试应该能够完全通过逻辑推理来解决所有问题。但是事实上，考过试的都知道，从阅读题目到形成解题思路的过程貌似并不那么“有逻辑”，甚至可以说是没有什么技巧可言，纯粹就是一种做题的感觉。\n两类知识 # 在现有知识的基础上，能够通过有限的符号逻辑表达式得到的知识；其特点就是精确，高度概括；问题边界明确，能够清晰定义已知条件有什么、通过什么样的方法、得出什么样的结果；在明确的已知条件下能够精准预测问题结果的规律（在问题的考虑范围内没有“概率”这个概念的容身之处）\n对于那些难以根据已知条件，通过精确的逻辑推理得到结果的问题，我们采用统计性的尝试，得出的有一定价值的规律；特点是基于大量尝试，难以定义问题的边界，甚至难以获取需要的已知条件，就是这种恶劣的条件下，强行匹配已知条件与结果的联系，进而得出的规律，其结果具有波动性、不确定性、局部正确性。\n两类知识的占比 # 明显可概括的知识远远少于不可概括的知识；可概括的知识从某种意义上来说是不可概括知识的特殊情况；\n不可概括向可概括转化的趋势 # 不可概括知识的特点决定了其获取的难度（大量尝试消耗大量能量，这一步不可避免），运转不可概括性知识的能量消耗极高（知识难以概括就会占用大量的资源来维持运转），不可概括的知识难以跨过人类个体生命的边界（不可概括的知识往往会随着个体生命的消散而丢失，因为其难以概括从而难以以任何媒介形式流传，但机器智能似乎在这方面有本质的区别）；人类个体的能量十分有限，难以完全依靠不可概括知识来应对外部世界，因此会有从不可概括知识向可概括知识转化的特点，尽管这个过程对于个体而言相当困难、极其耗费能量（本身就是一个不可概括的知识），但从整个人类的角度上来说节省了海量的能量；\n可接受功率决定了智能的上限 # 在这里似乎可以给出另外一个划分智能等级的标准：个体接受功率输入的级别，级别越高其，个体能掌握的不可概括知识越多；由于能量总是有限的（我们人类能消耗的能源级别可能是这个地球上面的资源，但是机器智能的消耗可能是恒星级别的），因此总会有一定程度上的知识概括，但是由于不可概括知识的固有性质，高等级智能的可概括知识对于低等级智能来说并不是可概括的；知识的可概括性具有相对性；\n从这里可以看出，可接受功率对于一个智能系统来说具有关键意义。从另一个角度来说，或许我们能够人为降低机器智能可消耗功率的上限来观察不可概括知识向可概括知识转化的过程\n","date":"2025-01-03","externalUrl":null,"permalink":"/blog/moravecs-paradox/","section":"Blogs","summary":"\u003ch2 class=\"relative group\"\u003e莫拉维克悖论 \n    \u003cdiv id=\"%E8%8E%AB%E6%8B%89%E7%BB%B4%E5%85%8B%E6%82%96%E8%AE%BA\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%8E%AB%E6%8B%89%E7%BB%B4%E5%85%8B%E6%82%96%E8%AE%BA\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e高水平的推理需要相对较少的计算资源，而低水平的感知和运动技能则需要大量的计算资源。\u003c/p\u003e","title":"关于莫拉维克悖论的思考","type":"blog"},{"content":" 前言 # 这篇文章主要是对于 CUMCM 2024 的比赛全过程进行一个梳理和总结。\n我们的队伍是在 2023 年的冬天组起来的，CUMCM 2024 也是我们第一次参与“数学建模”比赛。经过了大大小小的模拟赛，最终进入了全国的比赛。在提交最终论文之后获得省级一等奖并推荐国家级一等奖，最终获得国家级二等奖。\n整个过程有振奋惊喜，也有失落遗憾；我们在比赛中应该是做对了一部分事情，因此我们初次参赛就获得了国家级奖项；但不足肯定是有的，毕竟从“推荐国家级一等奖”变成“国家级二等奖”总是有理由的。\n总之，这次经历着实是令人难忘，更加值得梳理和总结经验，为明年的比赛作准备。\nCUMCM 全称为 Chinese Undergraduate Mathmatical Contest in Modeling；民间称呼为“数模国赛” 用词说明 # 用词 说明 计算系统 传统意义上的建模过程，即封装一个超大的函数 优化系统 用于优化计算系统中可调参数的系统，生成最优参数配置 计算流 计算系统中输入数据的处理过程 计算流结点 工作流中关键性的中间步骤 优化流 优化系统的主体逻辑 论文主体内容 包括摘要、重述、计算流和优化流的描述、结果展示与分析，也就是论文收尾之前的所有内容 论文收尾 包括灵敏度分析和模型推广 客观情况 # 任务分工 # 虽然比赛有很多个选题可供选择，但是我们小组选择专攻优化类问题，也就是 A 题。\n我：建模 + 代码 + 部分论文撰写 CL：建模 + 论文撰写 + 部分代码 HWJ：论文美化 工作流程 # 整个 A 题的代码部分大致可以分为两个系统：\n计算系统： 功能：接受输入数据与参数，返回需要的结果 性质：直接由题目决定，不同题目有不同的计算系统，需要临时构建 优化系统： 功能： 接受计算系统并将其作为可优化的目标函数，执行自身的优化逻辑，最后返回计算结果 性质：方法体系较为成熟，可以在比赛前就进行多种优化系统的准备 论文撰写部分分为：\n整体框架：由 LaTeX 模板决定 主体内容填充：对工作流和优化流的清晰描述 排版和美化：调整各个部分的详略，搭配说明性的图片（流程图，示意图） 收尾内容 预建模 # 目标：在精确理解题目的前提条件下，迅速进行初步的建模，基本确定建模方向、计算方法；\n预计用时：3h\n工作：队伍所有成员都进行全网资料查询，看看有没有基本命中题目的文献资料\n命中成功：最理想的情况，这个时候直接研读论文，收集思路即可； 命中失败：虽然没有现成的资料可供参考，但是在查阅文献的过程中或多或少也积累了一定的思路 建模初期 # 总目标：构建足够精确的、适配优化方法的计算系统\n建模：明确输入数据在各个计算流结点之间的操作 代码：用代码实现计算流，实现数据可视化 论文：填充第一个小问的内容，并初步排版 预计用时：30h\n工作：\n所有队员一起进行建模，优先明确建模思路，给出完整的数学推导过程 我和 CL：代码实现与论文内容填充同步进行 HWJ：绘制无法用代码生成的更加生动的示意图 建模中期 # 总目标：构建合适的优化系统\n建模：根据计算系统的特殊性，选择最为匹配的优化系统 代码：在实现优化系统的过程中进行微小改动，匹配计算系统 论文：完成论文的主体部分，开始进行局部细节微调 预计用时：20h\n工作：与前面类似只不过工作的中心从代码编写转到了论文撰写\n精简论文，此时的论文非常臃肿 微调论文的逻辑，使得上下文关联度更高 美化排版，减少文字，增加图片 建模后期 # 基本建模完成了，全员进行漏洞的检查： 错别字、不准确的表述、公式拼写错误等常规检查 优化代码中的注释，让其更加易读 重点检查个人信息 比赛论文中不能保留任何个人信息，包括代码中的文件路径，例如 C:\\Users\\Morethan ；保留个人信息是非常严重的错误！ 实战效果 # 当我们将上述策略应用于实战过程中，也就是 CUMCM 2024 的正式比赛中，得到的效果如下：\n有效用时： 比赛总时长三天，共计 72 小时 队伍从早上七点到晚上八点，除开吃饭用时，一天的有效时间为 12 个小时 时间利用率为 \\(50\\%\\)（对比之下很低🤔） 最终完成工作： 论文主体 28 页 A4 纸 代码部分 35 页 A4 纸，除开每一个小题之间的复用代码，应该有 20 页左右 全文配图共计 25 张 以上数据是论文精简之后的，初稿论文将近 50 页 未完成工作： 最终结果的计算，由于计算量过大（代码效率并不高），最终提前两个小时写完所有代码，但并没有足够的时间运算出结果😭😭 模型的计算精度不够，精度为 1s 没有达到标准答案给出的精度 论文的收尾部分其实并没有完成 优点 # 选题 # 专注于 A 题，在模拟赛中积累了充分的经验，磨合出了一套高效的工作流程\n对于 A 题的方法论构建比较完善\n工作流程 # 工作流程相对清晰，效率较高\n以最终论文为导向，建模、论文、代码三线同时进行，保证了论文内容的充足\n分工 # 采用模糊分工，每个队员都有一个主要分工和次要分工，在各自的主要分工上能够独立工作，在其他的次要分工上面也能够完成一定的工作，大大提高了时间利用率\n队员很给力，因为同时兼顾两个分工任务意味着更多的学习成本\n不足 # 工作流程 # 计划很完美，但是在实践中还是有些必要的环节没有做好\n有效时间占比：晚上八点收工太早了！应该占用更多的时间来进行建模试错，保证模型的正确性和精确性\n分工 # 代码的编写、代码的调试、代码的可视化、结果的计算、结果的可视化所涉及的代码量太大，一人难以搞定；\n因为模糊分工所引起的任务重叠，增加了协同成本\n建模 # 题目理解准确度：这次我们对于题目的理解出现了较大的偏差，导致我们浪费了挺多时间在模型修正上面； 代码 # 代码的效率：之前由于没有时间的限制，导致对于“超长”代码的准备不足，没有代码并行的经验；\n结果精度：一开始建模过于粗糙，并且用了一个不好的特性：将时间步长设置为 1 ，并且将作为数组索引，导致后期难以将时间的步长减小，导致最后结果的精确度不够\n改进方案 # 精心挑选场地，增加有效时间✨是最重要的✨ 分工 # 略微改动人员分工，增加代码方面的人力投入\n在各自的主要分工和次要分工上增加学习投入，增加工作效率\n建模 # 更专注于题目的理解，不能太着急；建模错误再修正是得不偿失的 代码 # 构建一套行之有效的代码协同方案，增强代码编写速度\n着手构建代码编写规范：\n变量命名 文件开头的说明文档 代码编写流程规范 代码并行化：在代码中添加一些可并行的代码，提高运行速度\n所有代码方面的改进最终落实为一个文档！不能光喊口号！ 落实后的方案：代码协同方案 论文 # 研究优秀论文\n关注其论文框架 关注其语言风格、文本可读性、详略、配图逻辑、图片可读性 改进自身\n优化论文主体逻辑框架，细化每一块的内容 语言风格、文本可读性、详略、配图逻辑、图片可读性等等细节的改进 成果以 LaTeX 模板中注释的形式固定！ 总结 # 一份没有满分的答卷比一份满分的答卷更有收获！\n积累应用数学的知识，增强论文撰写能力，提高发现问题的能力，这是比比赛本身更有意义的东西🫡\nCUMCM，每一个数模人都能从中受益🤗\n","date":"2024-09-12","externalUrl":null,"permalink":"/blog/cumcm2024/","section":"Blogs","summary":"\u003ch2 class=\"relative group\"\u003e前言 \n    \u003cdiv id=\"%E5%89%8D%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%89%8D%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e这篇文章主要是对于 CUMCM 2024 的比赛全过程进行一个梳理和总结。\u003c/p\u003e","title":"CUMCM 2024总结","type":"blog"},{"content":" 创建虚拟环境 # 常规 Python 操作 # 创建 # 一些常规的代码例子如下👇\n# 创建虚拟环境 python -m venv your_env_name # 指定python版本创建虚拟环境，如果你的python是默认安装路径 python -m venv your_env_name --python=python3.11 # python是自定义的安装路径 D:\\Python\\Python311\\python.exe -m venv your_env_name 下面有一些可选参数用于创建自定义的虚拟环境：\n参数名 含义 --system-site-packages 创建的虚拟环境将包含全局Python环境中的包，这可以避免重复安装一些常用的包 --clear 如果指定的虚拟环境目录已经存在，这会清除目录中的所有内容，然后重新创建虚拟环境 --version 用于确认虚拟环境中 Python 的版本 所有的参数说明都可以通过运行 python -m venv -h 来获得；不用到处查文档了~😆 激活 # 默认情况下，虚拟环境处于非激活状态。在“your_env_name/Scripts/”目录下将有一个名为“activate”的文件，用命令行运行即可。\n# 激活虚拟环境 your_env_name/Scripts/activate Poetry # Poetry 是一个 Python 的包管理工具，从更新日志来看，它从 2018 年 2 月就已经开始填充代码了，不算一个新的工具，但是最近几年非常流行💫\n其官方宣传的亮点如下：\n更佳详尽全面的第三方依赖包分析 自动化的虚拟环境创建 更佳符合直觉的命令🤔 安装 # 非常直接：pip install poetry，进行全局安装\n全局配置 # poetry 有一些非常特殊的机制，可能和 pip 等有些不太一样。你可能会需要去设置一下某些配置，具体如下：\n# 列举出所有配置项 poetry config --list # poetry默认将虚拟环境创建在一个专属的文件夹中，而不是项目目录中 # 使用下面的命令将环境文件夹创建在项目目录中 poetry config virtualenvs.in-project true # 当项目中没有虚拟环境的时候，poetry默认能够自动创建 # 不放心可以再运行一下这个命令 poetry config virtualenvs.create true # 更换国内源 poetry config repositories.tencentyun https://mirrors.tencentyun.com/pypi/simple # 其他的几乎不用关注，默认即可 初始化项目 # 如果你需要从头创建一个新的项目，那么你需要：创建一个项目文件夹，并把命令行的目录切换到那里，然后简单地：\npoetry init 交互式的命令行会指引你创建一个新的项目，创建 pyproject.toml 文件来记录依赖包，同时创建 poetry 的特色文件 poetry.lock 来锁定包版本。用过 Node 的同志应该比较熟悉😝\n如果你使用的是别人的项目，一般只会有 pyproject.toml 文件，这个文件在不同的包管理工具之间是通用的。当然也会有将 poetry.lock 也一并上传的作者，这种情况你可以选择：1）删掉 lock 文件然后用别的包管理工具；2）保留 lock 文件并使用 poetry 来管理依赖包\n如果你需要一个简单的目录框架，则可以使用：\npoetry new my-package 它会自动创建一个适合大多数项目的目录结构：\nmy-package ├── pyproject.toml ├── README.md ├── my_package │ └── __init__.py └── tests └── __init__.py 如果你有更加复杂的需求：new Command\n创建虚拟环境 # 这里就有几种情况可以说说。\n你是从头开始构建自己的项目 poetry env use python # 还记得你怎么安装poetry的吗？这里的Python默认那个版本 poetry env use python3.7 # 使用你系统中的Python3.7版本 poetry env use 3.7 # 懒癌专属 poetry env use /full/path/to/python # 如果上面的简写形式没法识别，用这个 你是使用别人的项目 有两个非常类似的命令，从下面的注释就可以看出二者的区别。官方更推荐 sync 命令，因为这样可以避免安装一些没有被 poetry.lock 追踪的包，这些包可能是原开发者不小心加进去的；\n但是实际测试下来更建议使用 install，因为 sync 有时会出现一些奇怪的错误，比如它把自己给移除了，导致命令行崩溃🤔\npoetry install # 自动创建虚拟环境并安装pyprojecy.toml中的所有依赖包 # 确保你的 virtualenvs.create 设置为 true # 自动创建虚拟环境并安装poetry.lock中的所有依赖包，移除pyproject.toml中多余的包 poetry sync 然后使用如下命令进入虚拟环境\npoetry shell 添加包 # poetry 允许开发者区分哪些包是生产环境需要的，哪些包只是开发环境需要的\n# 默认添加到生产环境组 poetry add your-package # 添加到开发环境组 poetry add your-package -D 更新包 # poetry update # 自动分析依赖并更新可能的所有包 poetry update your-package1 your-package2 # 只更新你列举的包 移除包 # 这个确实是 poetry 值得圈点的功能：pip 在安装时会安装你给出的包及其第三方依赖，但是在移除包的时候只会移除你列出的包，而无法移除其对应的第三方依赖。\npoetry 却能够安全完整地移除你的第三方依赖包，并且不影响别的依赖包。\n# 移除生产环境的包 poetry remove your-package # 移除开发环境的包 poetry remove your-package -D 显示依赖 # poetry show --tree # 展示pyproject.toml中的依赖树 poetry show your-package --tree # 展示特定包的依赖树 UV # 一款用 Rust 编写的包管理工具，命令格式与 poetry 极其类似。\n安装 # 首先需要配置环境变量：\ncd ~ # 确保你在默认目录下 ls -a # 查看是否存在文件.bashrc vim .bashrc # vim编辑文件 # 文件末尾附加下面这三条 # installer的国内下载源 export UV_INSTALLER_GHE_BASE_URL=https://ghproxy.cn/https://github.com # python install国内下载源 export UV_PYTHON_INSTALL_MIRROR=https://ghproxy.cn/https://github.com/indygreg/python-build-standalone/releases/download # python包国内下载源 export UV_DEFAULT_INDEX=https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple curl安装（推荐）： # 注意把\u0026#34;/custom/path\u0026#34;换成你自定义的安装位置 curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR=\u0026#34;/custom/path\u0026#34; sh pip/pipx安装（推荐）： pipx install uv # 使用pipx安装uv pip install uv # 使用pip安装uv 使用 # 使用方式与 poetry 非常类似\nConda # 我个人较少使用 conda 来管理环境，但是鉴于很多实验室服务器上都默认使用 conda 因此也做一个记录\n使用 # 下面的命令是基础的查看环境信息的命令，一般在进入一个新的服务器环境的时候就会使用一遍，在排查环境问题的时候也会使用。\n########## 查看环境信息 ########## arch # 查看系统架构 conda --version # 获取conda版本号 python --version # 获取python版本号 conda env list # 查看当前所有环境 conda activate xxx # 激活名为xxx的虚拟环境 conda deactivate # 退出当前虚拟环境 whereis python # 查看当前激活环境中的python位置 nvidia-smi # 查看cuda运行情况，不算conda的命令但很常用 conda config --show channels # 查看conda下载源 conda remove -n xxx # 删除环境名为xxx的虚拟环境 conda create -n 环境名 # 创建环境名为xxx的虚拟环境，使用默认python版本 添加国内下载源：\nconda config --show channels # 查看conda下载源 # 添加清华源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 管理 python 包：\n# 安装指定包 conda install package_name # 移除指定包 conda remove package_name # 更新指定包 conda update package_name # 搜索指定包 conda search package_name # 列出所有包的名称及版本 conda list # 删除未使用的包和缓存，节省磁盘空间 conda clean --all # 根据文件中的列表安装包 conda install -f requirements.txt 手动安装依赖包，用于应对极端断网情况：\n# 直接使用pip download命令下载所有相关whl文件 pip download scikit-image --dest ./scikit_image_files --only-binary :all: --python-version 3.13 --platform manylinux_2_17_x86_64 --implementation cp --abi cp313 # 手动传输到服务器上，切到对应文件夹然后运行，注意whl # --find-links指定whl所在的文件夹 pip install scikit_image-0.25.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-index --find-links=./ 注意不要改 whl 文件的名字😢 VS免密登录 # 对于没有本地 GPU 的学生党来说，直接在服务器上编辑并运行文件是非常方便的，而 VSCode 插件 remote-ssh 也能够在服务器上直接呈现一个 VSCode 的界面。为了省去不断输入密码的痛苦，可以进行如下操作实现免密登录😄\n本地机为 Windows，一般来说在 C:\\Users\\\u0026lt;User_name\u0026gt;\\.ssh 文件夹中会存放 ssh 相关的配置文件，实现免密登录就只需要操作这里面的文件即可。\n配置 config 文件，样例配置如下： # 把\u0026lt;User_name\u0026gt;替换为你的本地机用户名 Host 3090 HostName xx.xxx.xx.xx User morethan IdentityFile \u0026#34;C:\\Users\\\u0026lt;User_name\u0026gt;\\.ssh\\id_rsa\u0026#34; 生成验证文件 id_rsa.pub\n本地创建 authorized_keys 文件，并将 id_rsa.pub 中的内容写入这个文件\n在服务器中默认目录下创建 .ssh 文件夹，然后将 authorized_keys 文件从本地拷贝进去即可\n然后用 VSCode 登录服务器就发现已经完成了免密登录\n上述繁琐的步骤只需要初次执行一次就行，当需要给下一台服务器配置免密登录时，只需要改 config 文件然后把 authorized_keys 文件拷贝到服务器就完成了，不需要改写任何文件😄 程序打包 # 我们经常需要把自己写的 Python 程序分享出去。然而只分享源代码会使得不太懂代码的用户非常苦恼，因为源代码的运行还需要搭建本地运行环境，因此打包程序应运而生。\npyinstaller # 安装非常简单，就像别的 Python 包一样 pip install pyinstaller 即可；使用时在目标文件所在的目录启动终端，然后运行命令即可。\n特点：打包速度较快；打包后的程序较大\n常见的命令代码：\n# 将main.py文件打包为一个独立的可执行文件；可执行文件运行后禁用命令行窗口 pyinstaller -F -w main.py # 将main.py文件打包为一个工程文件夹；可执行文件运行后启用命令行窗口 pyinstaller -D main.py 参数 说明 -h, --help 显示帮助信息并退出 -v, --version 显示程序版本信息并退出 -F, --onefile 将所有内容打包为一个独立的可执行文件 -D, --onedir 将所有内容打包为一个目录（默认选项） -w, --windowed, --noconsole 禁用命令行窗口（仅对 Windows 有效） -c, --console, --nowindowed 使用命令行窗口运行程序（默认选项，仅对 Windows 有效） -a, --ascii 不包含 Unicode 字符集支持（默认包含） -d, --debug 产生 debug 版本的可执行文件 -n NAME, --name=NAME 指定生成的可执行文件或目录的名称（默认为脚本名称） -o DIR, --out=DIR 指定 spec 文件的生成目录（默认为当前目录） -p DIR, --path=DIR 设置 Python 导入模块的路径（类似设置 PYTHONPATH） -i \u0026lt;FILE\u0026gt;, --icon \u0026lt;FILE\u0026gt; 设置可执行文件的图标（支持 .ico 或 .icns 格式） --distpath DIR 指定生成的可执行文件的输出目录（默认为 ./dist） --workpath WORKPATH 指定临时工作文件的目录（默认为 ./build） --add-data \u0026lt;SRC;DEST or SRC:DEST\u0026gt; 添加额外的数据文件或目录到可执行文件中（Windows 使用分号，Linux/OSX 使用冒号分隔源路径和目标路径） --add-binary \u0026lt;SRC;DEST or SRC:DEST\u0026gt; 添加额外的二进制文件到可执行文件中 --hidden-import MODULENAME 添加未自动检测到的模块 --exclude-module EXCLUDES 排除指定的模块 --clean 清理 PyInstaller 缓存和临时文件 --log-level LEVEL 设置构建时控制台消息的详细程度（可选值：TRACE、DEBUG、INFO、WARN、ERROR、FATAL） Nuitka # 将 Python 代码打包为 exe 可执行文件，转换原理是先将 Python 代码转换为 C 代码，然后再编译 C 代码。\n特点：打包速度相当慢；需要额外安装 C 编译器，尽管可以自动完成但是对于内存空间管理非常严格的用户并不适用；打包后的程序体积很小（实测是 pyinstaller 的十分之一）\n安装命令：\npip install -U nuitka 常见使用命令：\n# 将main.py文件打包为一个exe文件，使用链式优化，完成打包后清理临时文件 python -m nuitka --lto=yes --remove-output --onefile main.py 参数 说明 --standalone 创建一个包含所有依赖的独立可执行文件夹。 --onefile 将所有内容打包为一个单独的 .exe 文件。 --optimize=N 设置优化级别（0、1 或 2），数字越大，优化越多。 --lto 启用链接时优化（Link Time Optimization），可选值为 no、yes 或 thin。 --enable-plugin=\u0026lt;plugin_name\u0026gt; 启用指定插件，如 tk-inter、numpy、anti-bloat 等。 --output-dir=\u0026lt;dir\u0026gt; 指定编译输出目录。 --remove-output 编译完成后删除中间生成的 .c 文件和其他临时文件。 --nofollow-imports 不递归处理任何导入模块。 --include-package=\u0026lt;package_name\u0026gt; 显式包含整个包及其子模块。 --include-module=\u0026lt;module_name\u0026gt; 显式包含单个模块。 --follow-import-to=\u0026lt;module/package\u0026gt; 指定递归处理的模块或包。 --nofollow-import-to=\u0026lt;module/package\u0026gt; 指定不递归处理的模块或包。 --include-data-files=\u0026lt;source\u0026gt;=\u0026lt;dest\u0026gt; 包含指定的数据文件。 --include-data-dir=\u0026lt;directory\u0026gt; 包含整个目录的数据文件。 --noinclude-data-files=\u0026lt;pattern\u0026gt; 排除匹配模式的数据文件。 --windows-icon-from-ico=\u0026lt;path\u0026gt; 设置 Windows 可执行文件的图标。 --company-name, --product-name, --file-version, --product-version, --file-description 设置 Windows 可执行文件的属性。 参考资料 # Poetry 相关：\npoetry 入门完全指南_poetry使用-CSDN博客非常详细的资料 Poetry poetry如何更换国内源-数据科学SourceResearch UV 相关：\nPython 项目和包管理器 uv 安装以及使用 - 深海小涛为数不多的写了 uv python install 国内源地址的博客 Conda 相关：\nconda常用命令的总结 - 知乎 ","date":"2024-08-10","externalUrl":null,"permalink":"/blog/pytips/","section":"Blogs","summary":"\u003ch2 class=\"relative group\"\u003e创建虚拟环境 \n    \u003cdiv id=\"%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\n\n\u003ch3 class=\"relative group\"\u003e常规 Python 操作 \n    \u003cdiv id=\"%E5%B8%B8%E8%A7%84-python-%E6%93%8D%E4%BD%9C\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%B8%B8%E8%A7%84-python-%E6%93%8D%E4%BD%9C\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\n\n\u003ch4 class=\"relative group\"\u003e创建 \n    \u003cdiv id=\"%E5%88%9B%E5%BB%BA\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%88%9B%E5%BB%BA\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h4\u003e\n\u003cp\u003e一些常规的代码例子如下👇\u003c/p\u003e","title":"Python小技巧","type":"blog"},{"content":" 引用文献 # 我对于贝叶斯优化的理解也并不多，主要参考下面的内容👇\n【机器学习】一文看懂贝叶斯优化/Bayesian Optimization\n一文详解贝叶斯优化（Bayesian Optimization）原理\n贝叶斯优化(BayesianOptimization)\n超参数优\u0026mdash;贝叶斯优化及其改进（PBT优化）\n贝叶斯优化 (Bayesian Optimization)\nMATLAB官方文档\nExploring Bayesian Optimization\n优点和算法原理 # 这里重点描述贝叶斯优化的优点以及其算法原理。如果你只关注“怎么用”，可以先了解贝叶斯优化的优点，然后跳转到 MATLAB用法\n优点 # 算法原理 # MATLAB用法 # 代码一览 # % 定义目标函数 function y = objectiveFcn(x) y = (1 - x.x1)^2 + 100 * (x.x2 - x.x1^2)^2; end % 定义优化变量 vars = [optimizableVariable(\u0026#39;x1\u0026#39;, [-2, 2]) optimizableVariable(\u0026#39;x2\u0026#39;, [-2, 2])]; % 执行贝叶斯优化 results = bayesopt(@objectiveFcn, vars, ... \u0026#39;AcquisitionFunctionName\u0026#39;, \u0026#39;expected-improvement-plus\u0026#39;, ... \u0026#39;MaxObjectiveEvaluations\u0026#39;, 30, ... \u0026#39;IsObjectiveDeterministic\u0026#39;, true, ... \u0026#39;Verbose\u0026#39;, 1); % 查看结果 bestPoint = results.XAtMinObjective; bestObjective = results.MinObjective; fprintf(\u0026#39;最优解 x1: %.4f, x2: %.4f\\n\u0026#39;, bestPoint.x1, bestPoint.x2); fprintf(\u0026#39;最优目标值: %.4f\\n\u0026#39;, bestObjective); 参数说明 # Params Meaning AcquisitionFunctionName 选择采集函数，这决定了算法在每次采样之后如何选取下一个采样点 MaxObjectiveEvaluations 最大迭代轮次 IsObjectiveDeterministic 如果目标函数是确定的，不包含噪声，则设置为 true ；否则设置为 false Verbose 决定了结果输出的详细程度，所有的输出可能包含多张图表 每个参数具体的可选值见官方文档: bayesopt；官方写的相当细致，还有很多样例。\n数学建模人必会技能之一就是读文档😝 ","date":"2024-08-05","externalUrl":null,"permalink":"/blog/bayesianopt/","section":"Blogs","summary":"\u003ch2 class=\"relative group\"\u003e引用文献 \n    \u003cdiv id=\"%E5%BC%95%E7%94%A8%E6%96%87%E7%8C%AE\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BC%95%E7%94%A8%E6%96%87%E7%8C%AE\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e我对于贝叶斯优化的理解也并不多，主要参考下面的内容👇\u003c/p\u003e","title":"贝叶斯优化","type":"blog"},{"content":" 背景提要 # 你应该知道如何通过命令行与电脑交互，包括但不限于：Windows如何唤出命令行/终端，正在运行中的命令什么时候结束\u0026hellip;\u0026hellip;\n懂一点点翻墙的技术，OverLeaf是个国外的软件,与之硬相关的latex项目也是国外的，因此下载相关依赖的时候能够直接接受国外流量会省掉很多麻烦。如果你没有VPN的话就需要为每一个包管理工具指定一个国内源，但有时候国内源更新并不及时。\n懂一些Vim的基本操作，比如：如何开启插入模式，如何保存退出，不保存退出等\n部署全流程 # 安装Linux # 在 Windows App Store 里面直接搜索一个Linux发行版本并下载，笔者选择的是Kali。安装完成后可以在开始菜单中直接打开，打开后会跳出命令行窗口，初次打开需要填写需要用户名与密码进行注册。\n此时你的命令行应该有一个 Warning 提示。这是因为你还没有安装 WSL(Windows Subsystem for Linux)；同时，在填写密码的时候你的输入不会显示在命令行，但已经被记录了 为什么需要一个Linux系统？因为OverLeaf的sharelatex模型需要Linux环境。也正因如此，据说在Linux系统上运行的OverLeaf更加流畅。\n安装WSL # 安装WSL2，直接在Windows命令行中运行：\nwsl --install 这个程序安装后也可以直接打开，打开后也有一个Warning提示。这时候需要在 C:\\Users\\ASUS 目录下面写入一个text文件，然后重命名为 .wslconfig；\n写入内容为：\n[experimental] autoMemoryReclaim=gradual # gradual | dropcache | disabled networkingMode=mirrored dnsTunneling=true firewall=true autoProxy=true 安装Docker # 进入 Docker 官网下载Docker，这是sharelatex模型运行的容器。Docker是一个开源的应用容器引擎，其中包括，镜像、容器、仓库，目的就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的产品及其环境能够做到“一次封装，到处运行”。就像一个集装箱，由程序员开发并封装，用户使用时就直接把整个集装箱搬过去。\nDocker安装完成后就可以双击启动放后台了，我们后面通过命令行来操作Docker；\n拉取镜像 # 打开 Kali，直接运行\ngit clone https://github.com/overleaf/toolkit.git ./overleaf-toolkit 然后连续运行：\ncd ./overleaf-toolkit bin/init vim ./config/variables.env 此时你应该已经进入了一个文档界面，这就是Vim文本编辑器的界面。Vim有很多快捷键，其中按下\u0026quot;I\u0026quot;键即可开启插入模式，进行文本编辑，按下\u0026quot;esc\u0026quot;即可返回常规模式。在插入模式下输入：OVERLEAF_SITE_LANGUAGE=zh-CN\n输入完成后按下\u0026quot;esc\u0026quot;返回常规模式，直接键入 :wq 这是“保存并退出”，如果你不小心输错了可以 :e! 放弃所有更改重头再来。这一步是让你的OverLeaf界面显示为中文。\n当你成功保存并退出，回到熟悉的Kali命令行界面后运行 bin/up 此时正在拉取sharelatex镜像以及相关的网络工具。这时会有大量的数据传输，要保证网络通畅（梯子要稳！）\n配置用户 # 当上一个命令成功结束之后，运行 bin/start ；此时你打开Docker点进sharelatex，你应该可以看到代码“爆闪”，如果没有红色的消息，那应该是正常运行了。\n这时打开浏览器访问网址 http://localhost/launchpad\n按照提示注册Administrator Account之后，就会跳转到 http://localhost/project ；这时基本的OverLeaf网页已经可以显示了。\n但现在你丢一个文件进去编译多半是会报错的 ᕕ( ᐛ )ᕗ ；因为此时 sharelatex 里面的宏包严重不足，不是红包「手动狗头」 安装扩展包 # 打开 Kali 进入对应目录运行 bin/shell 然后逐条执行：\ncd /usr/local/texlive # 下载并运行升级脚本 wget http://mirror.ctan.org/systems/texlive/tlnet/update-tlmgr-latest.sh sh update-tlmgr-latest.sh -- --upgrade # 更换texlive的下载源 tlmgr option repository https://mirrors.sustech.edu.cn/CTAN/systems/texlive/tlnet/ # 升级tlmgr tlmgr update --self --all # 安装完整版texlive（时间比较长，不要让shell断开） tlmgr install scheme-full # 退出sharelatex的命令行界面 exit # 重启sharelatex容器 docker restart sharelatex 重启后再次进入 shell，运行：\napt update # 安装字体 apt install --no-install-recommends ttf-mscorefonts-installe fonts-noto texlive-fonts-recommended tex-gyre fonts-wqy-microhei fonts-wqy-zenhei fonts-noto-cjk fonts-noto-cjk-extra fonts-noto-color-emoji fonts-noto-extra fonts-noto-ui-core fonts-noto-ui-extra fonts-noto-unhinted fonts-texgyre # 安装pygments apt install python3-pygments # 安装beamer之类的 apt install texlive-latex-recommended apt install texlive-latex-extra # 安装英文字体 echo \u0026#34;yes\u0026#34; | apt install -y --reinstall ttf-mscorefonts-installer # 安装中文字体 apt install -y latex-cjk-all texlive-lang-chinese texlive-lang-english cp fonts/* /usr/share/fonts/zh-cn/ cd /usr/share/fonts fc-cache -fv # 更新字体缓存 fc-list :lang=zh-cn fc-match Arial 最后在 shell 目录里面运行：\nvim /usr/local/texlive/2023/texmf.cnf 进入配置文件，在最底下加入一句 shell_escape = t\n我也不知道这有什么用，属于是前辈传承了🤔 注意，如果Texlive(扩展包的官名)版本不同的话，目录地址也会有所变化，因此需要根据实际的地址来填写，例如将2023改成2024。\n在Linux命令行中可以用 ls -l 来查看当前目录下所有的文件 部署成功 # 现在你就可以愉快地使用本地版OverLeaf了，没有编译超时的困扰~\n如果非常巧合，你也是个CQUer，这里附赠一份重庆大学的毕业论文模板，炒鸡的亲民哦：CQUThesis\n","date":"2024-07-12","externalUrl":null,"permalink":"/blog/localoverleaf/","section":"Blogs","summary":"\u003ch2 class=\"relative group\"\u003e背景提要 \n    \u003cdiv id=\"%E8%83%8C%E6%99%AF%E6%8F%90%E8%A6%81\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E8%83%8C%E6%99%AF%E6%8F%90%E8%A6%81\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e你应该知道如何通过命令行与电脑交互，包括但不限于：Windows如何唤出命令行/终端，正在运行中的命令什么时候结束\u0026hellip;\u0026hellip;\u003c/p\u003e","title":"本地 OverLeaf 部署","type":"blog"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/blog/","section":"Blogs","summary":"","title":"Blogs","type":"blog"},{"content":" 欢迎来到我的信息页面 👋 # 基本信息 # Morethan 是我随手起的一个英文名字，因为这个词语的发音和我的中文名字实在是太像了🙃\n我现在还是一个本科生 ᕕ( ᐛ )ᕗ 其他的没什么好写的🫠\n博客定位 # 个人知识库：用来存放一些固定的技术流程和有意义的经历\n微型论文栈：尽可能按照标准论文流程来编写一些博客，为毕业论文做准备\n知识输出平台：将我所学尽可能清晰地表达出来\n最后 # 如果你觉得有内容帮助了你，请点击文章开头的“喜欢” 🤗\n如果你想分享某些内容，请标注援引自此网站 🫡\n如果你找到了一些错误之处，请在 GitHub 上提交一个Issue 🥰\n","date":"2025-05-14","externalUrl":null,"permalink":"/authors/morethan/","section":"作者列表","summary":"\u003ch1 class=\"relative group\"\u003e欢迎来到我的信息页面 👋 \n    \u003cdiv id=\"%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E6%88%91%E7%9A%84%E4%BF%A1%E6%81%AF%E9%A1%B5%E9%9D%A2-\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E6%88%91%E7%9A%84%E4%BF%A1%E6%81%AF%E9%A1%B5%E9%9D%A2-\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e基本信息 \n    \u003cdiv id=\"%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMorethan\u003c/code\u003e 是我随手起的一个英文名字，因为这个词语的发音和我的中文名字实在是太像了🙃\u003c/p\u003e","title":"Morethan","type":"authors"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/tags/%E7%AC%94%E8%AE%B0/","section":"标签","summary":"","title":"笔记","type":"tags"},{"content":" ","date":"2025-05-14","externalUrl":null,"permalink":"/tags/","section":"标签","summary":"\u003chr\u003e","title":"标签","type":"tags"},{"content":"这里存放着一些学习笔记与微型论文，通过知识输出来达到知识巩固的目的。\n透过这些文字希望你也能有所收获🤗\n","date":"2025-05-14","externalUrl":null,"permalink":"/","section":"欢迎来到Morethan的小站","summary":"\u003cp\u003e这里存放着一些学习笔记与微型论文，通过知识输出来达到知识巩固的目的。\u003c/p\u003e","title":"欢迎来到Morethan的小站","type":"page"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/tags/%E6%9E%B6%E6%9E%84/","section":"标签","summary":"","title":"架构","type":"tags"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/tags/%E8%AE%BA%E6%96%87/","section":"标签","summary":"","title":"论文","type":"tags"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/series/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/","section":"系列","summary":"","title":"论文笔记","type":"series"},{"content":" ","date":"2025-05-14","externalUrl":null,"permalink":"/series/","section":"系列","summary":"\u003chr\u003e","title":"系列","type":"series"},{"content":"","date":"2025-05-14","externalUrl":null,"permalink":"/authors/","section":"作者列表","summary":"","title":"作者列表","type":"authors"},{"content":"","date":"4 May 2025","externalUrl":null,"permalink":"/en/series/ai-musings/","section":"Seires","summary":"","title":"AI Musings","type":"series"},{"content":"","date":"2025-05-04","externalUrl":null,"permalink":"/series/ai%E9%81%90%E6%83%B3/","section":"系列","summary":"","title":"AI遐想","type":"series"},{"content":"","date":"4 May 2025","externalUrl":null,"permalink":"/en/tags/blog/","section":"Tags","summary":"","title":"Blog","type":"tags"},{"content":"","date":"2025-05-04","externalUrl":null,"permalink":"/tags/llm/","section":"标签","summary":"","title":"LLM","type":"tags"},{"content":"","date":"2025-05-04","externalUrl":null,"permalink":"/tags/%E5%8D%9A%E5%AE%A2/","section":"标签","summary":"","title":"博客","type":"tags"},{"content":"","date":"2025-05-01","externalUrl":null,"permalink":"/tags/linux/","section":"标签","summary":"","title":"Linux","type":"tags"},{"content":"","date":"1 May 2025","externalUrl":null,"permalink":"/en/series/technical-miscellany/","section":"Seires","summary":"","title":"Technical Miscellany","type":"series"},{"content":"","date":"2025-05-01","externalUrl":null,"permalink":"/tags/ubuntu/","section":"标签","summary":"","title":"Ubuntu","type":"tags"},{"content":"","date":"2025-05-01","externalUrl":null,"permalink":"/series/%E6%8A%80%E6%9C%AF%E6%9D%82%E9%A1%B9/","section":"系列","summary":"","title":"技术杂项","type":"series"},{"content":"","date":"2025-03-20","externalUrl":null,"permalink":"/tags/mcts/","section":"标签","summary":"","title":"MCTS","type":"tags"},{"content":"","date":"20 March 2025","externalUrl":null,"permalink":"/en/tags/notes/","section":"Tags","summary":"","title":"Notes","type":"tags"},{"content":"","date":"20 March 2025","externalUrl":null,"permalink":"/en/tags/paper/","section":"Tags","summary":"","title":"Paper","type":"tags"},{"content":"","date":"20 March 2025","externalUrl":null,"permalink":"/en/series/paper-notes/","section":"Seires","summary":"","title":"Paper Notes","type":"series"},{"content":"","date":"20 March 2025","externalUrl":null,"permalink":"/en/tags/reasoningenhance/","section":"Tags","summary":"","title":"ReasoningEnhance","type":"tags"},{"content":"","date":"2025-03-20","externalUrl":null,"permalink":"/tags/%E6%8E%A8%E7%90%86%E5%A2%9E%E5%BC%BA/","section":"标签","summary":"","title":"推理增强","type":"tags"},{"content":"","date":"6 March 2025","externalUrl":null,"permalink":"/en/series/ai-project/","section":"Seires","summary":"","title":"AI-Project","type":"series"},{"content":"所有AI相关的工程性知识都汇聚于此🙌\n然而大部分都是基础性的知识，并非AI时代的产物🤔\n","date":"2025-03-06","externalUrl":null,"permalink":"/series/ai%E5%B7%A5%E7%A8%8B/","section":"系列","summary":"\u003cp\u003e所有AI相关的工程性知识都汇聚于此🙌\u003c/p\u003e\n\u003cp\u003e然而大部分都是基础性的知识，并非AI时代的产物🤔\u003c/p\u003e","title":"AI工程","type":"series"},{"content":"","date":"6 March 2025","externalUrl":null,"permalink":"/en/tags/cloud-service/","section":"Tags","summary":"","title":"Cloud-Service","type":"tags"},{"content":"","date":"2025-03-06","externalUrl":null,"permalink":"/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1/","section":"标签","summary":"","title":"云服务","type":"tags"},{"content":"","date":"2025-03-05","externalUrl":null,"permalink":"/tags/qdrant/","section":"标签","summary":"","title":"Qdrant","type":"tags"},{"content":"","date":"4 March 2025","externalUrl":null,"permalink":"/en/tags/full-stack/","section":"Tags","summary":"","title":"Full-Stack","type":"tags"},{"content":"","date":"2025-03-04","externalUrl":null,"permalink":"/tags/%E5%85%A8%E6%A0%88%E5%BC%80%E5%8F%91/","section":"标签","summary":"","title":"全栈开发","type":"tags"},{"content":"","date":"2025-02-05","externalUrl":null,"permalink":"/tags/neo4j/","section":"标签","summary":"","title":"Neo4j","type":"tags"},{"content":"","date":"27 January 2025","externalUrl":null,"permalink":"/en/tags/management/","section":"Tags","summary":"","title":"Management","type":"tags"},{"content":"","date":"27 January 2025","externalUrl":null,"permalink":"/en/series/project-reports/","section":"Seires","summary":"","title":"Project Reports","type":"series"},{"content":"","date":"27 January 2025","externalUrl":null,"permalink":"/en/tags/report/","section":"Tags","summary":"","title":"Report","type":"tags"},{"content":"","date":"27 January 2025","externalUrl":null,"permalink":"/en/tags/schedule/","section":"Tags","summary":"","title":"Schedule","type":"tags"},{"content":"","date":"2025-01-27","externalUrl":null,"permalink":"/tags/%E6%8A%A5%E5%91%8A/","section":"标签","summary":"","title":"报告","type":"tags"},{"content":"","date":"2025-01-27","externalUrl":null,"permalink":"/tags/%E6%97%A5%E7%A8%8B%E7%AE%A1%E7%90%86/","section":"标签","summary":"","title":"日程管理","type":"tags"},{"content":"","date":"2025-01-27","externalUrl":null,"permalink":"/series/%E9%A1%B9%E7%9B%AE%E6%8A%A5%E5%91%8A/","section":"系列","summary":"","title":"项目报告","type":"series"},{"content":"CUMCM 英文全称为 Chinese Undergraduate Mathmatical Contest in Modeling，中文全称为“全国大学生数学建模竞赛”。\n由于这个比赛并不能直接参与国家级总决赛，而是要经过校赛省赛的选拔，然后你的论文才会被交给全国的专家进行评审。因此这个比赛民间细分为三个，即数模校赛，数模省赛和数模国赛。\n","date":"2025-01-16","externalUrl":null,"permalink":"/tags/cumcm/","section":"标签","summary":"\u003cp\u003e\u003ccode\u003eCUMCM\u003c/code\u003e 英文全称为 Chinese Undergraduate Mathmatical Contest in Modeling，中文全称为“全国大学生数学建模竞赛”。\u003c/p\u003e","title":"CUMCM","type":"tags"},{"content":"","date":"16 January 2025","externalUrl":null,"permalink":"/en/series/mathmodel/","section":"Seires","summary":"","title":"MathModel","type":"series"},{"content":"","date":"2025-01-16","externalUrl":null,"permalink":"/tags/matlab/","section":"标签","summary":"","title":"MATLAB","type":"tags"},{"content":"数学建模 就是使用数学模型来精确地、系统地描述生活中的对象，是数学与实践的重要结合。\n","date":"2025-01-16","externalUrl":null,"permalink":"/series/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/","section":"系列","summary":"\u003cp\u003e\u003ccode\u003e数学建模\u003c/code\u003e 就是使用数学模型来\u003cstrong\u003e精确地、系统地\u003c/strong\u003e描述生活中的对象，是数学与实践的重要结合。\u003c/p\u003e","title":"数学建模","type":"series"},{"content":"","date":"2025-01-15","externalUrl":null,"permalink":"/tags/mysql/","section":"标签","summary":"","title":"MySQL","type":"tags"},{"content":"","date":"2025-01-10","externalUrl":null,"permalink":"/tags/hugo/","section":"标签","summary":"","title":"Hugo","type":"tags"},{"content":"","date":"6 January 2025","externalUrl":null,"permalink":"/en/series/casual-essay/","section":"Seires","summary":"","title":"Casual Essay","type":"series"},{"content":"","date":"6 January 2025","externalUrl":null,"permalink":"/en/tags/experience/","section":"Tags","summary":"","title":"Experience","type":"tags"},{"content":"","date":"2025-01-06","externalUrl":null,"permalink":"/tags/%E7%BB%8F%E5%8E%86/","section":"标签","summary":"","title":"经历","type":"tags"},{"content":"","date":"2025-01-06","externalUrl":null,"permalink":"/series/%E9%9A%8F%E7%AC%94/","section":"系列","summary":"","title":"随笔","type":"series"},{"content":"","date":"2025-01-03","externalUrl":null,"permalink":"/tags/ai/","section":"标签","summary":"","title":"AI","type":"tags"},{"content":"","date":"3 January 2025","externalUrl":null,"permalink":"/en/tags/imagination/","section":"Tags","summary":"","title":"Imagination","type":"tags"},{"content":"","date":"2025-01-03","externalUrl":null,"permalink":"/tags/%E9%81%90%E6%83%B3/","section":"标签","summary":"","title":"遐想","type":"tags"},{"content":"","date":"2024-09-12","externalUrl":null,"permalink":"/tags/math/","section":"标签","summary":"","title":"Math","type":"tags"},{"content":"","date":"2024-08-10","externalUrl":null,"permalink":"/tags/python/","section":"标签","summary":"","title":"Python","type":"tags"},{"content":"","date":"2024-07-12","externalUrl":null,"permalink":"/tags/latex/","section":"标签","summary":"","title":"LaTeX","type":"tags"},{"content":"","date":"2024-07-12","externalUrl":null,"permalink":"/tags/overleaf/","section":"标签","summary":"","title":"Overleaf","type":"tags"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]