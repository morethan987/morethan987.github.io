<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on More&#39;s awesome website</title>
    <link>https://morethan987.github.io/en/tags/llm/</link>
    <description>Recent content in LLM on More&#39;s awesome website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>morthan@qq.com (Morethan)</managingEditor>
    <webMaster>morthan@qq.com (Morethan)</webMaster>
    <copyright>© 2025 Morethan</copyright>
    <lastBuildDate>Sun, 04 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://morethan987.github.io/en/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>On the Memory of LLM</title>
      <link>https://morethan987.github.io/en/blog/llm-memory/</link>
      <pubDate>Sun, 04 May 2025 00:00:00 +0000</pubDate>
      <author>morthan@qq.com (Morethan)</author>
      <guid>https://morethan987.github.io/en/blog/llm-memory/</guid>
      <description>&lt;div class=&#34;lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl&#34;&gt;
  A summary of thoughts on the memory of large language models
&lt;/div&gt;



&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;This reflection originates from a common issue encountered in AI-assisted programming: the need to repeatedly familiarize itself with the code repository from scratch.&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://morethan987.github.io/blog/llm-memory/featured.svg" />
    </item>
    
    <item>
      <title>A Guide to Independent Full-Stack Development Driven by LLM Applications</title>
      <link>https://morethan987.github.io/en/blog/llm-app-driven-fullstack-dev/</link>
      <pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate>
      <author>morthan@qq.com (Morethan)</author>
      <guid>https://morethan987.github.io/en/blog/llm-app-driven-fullstack-dev/</guid>
      <description>&lt;div class=&#34;lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl&#34;&gt;
  This is an independent full-stack development journey, driven by the goal of building an LLM application. It covers various issues encountered during development.
It&amp;rsquo;s also the introductory article—article zero—of the &amp;ldquo;AI Engineering&amp;rdquo; series, serving both as an index to the series and a summary of personal insights.
&lt;/div&gt;



&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Nowadays, we&amp;rsquo;ve become accustomed to effortlessly interacting with AI chat assistants like Doubao, Kimi, and DeepSeek. It seems like creating something similar ourselves shouldn&amp;rsquo;t be too difficult, right?&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://morethan987.github.io/blog/llm-app-driven-fullstack-dev/featured.svg" />
    </item>
    
  </channel>
</rss>
